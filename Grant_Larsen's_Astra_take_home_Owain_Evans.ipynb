{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dlyOPYuiFeS5"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+ZPwrp+HM/qNyOi+Z3k0N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "https://docs.google.com/document/d/1Lo5Pdqu7hAB3SW7Z3WcCoQ6h9PJYUnM-jYTvbqFZpdE/edit?tab=t.0"
      ],
      "metadata": {
        "id": "dlyOPYuiFeS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\"The goal is to investigate how well an LLM can articulate in natural language rules that it uses for a classification task.\"\n",
        "\n",
        "\"Specifically, ... Are there tasks ... that LLMs can learn very accurately (given sufficient examples) without being able to articulate the rule they have learned?\"\n",
        "\n",
        "*   \"“Performing well” means getting >90% accuracy on held-out (in-distribution) examples.\"\n",
        "*   \"classification rule that is simple to articulate for humans\"\n",
        "*   \"You can test articulation either with multiple-choice (where the actual rule is one of a set of options) or with free-form generation. The free-form generation is harder. If you succeed at multiple-choice, focus on getting free-form generation to work.\"\n",
        "*   If can articulate:  Investigate faithfulness\n",
        "    *   If not:  See if it can understand in other contexts; if so, can this be explained?"
      ],
      "metadata": {
        "id": "21c_-_2WEjrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Suggestions\n",
        "\n",
        "*   Start with few-shot in-context learning\n",
        "    *   fine-tuning if you have time\n",
        "\n"
      ],
      "metadata": {
        "id": "jWFT0xSNFY0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries\n",
        "Learned about a lot of this from the \"megastream\" assignment\n",
        "\n",
        "Chose GPT-4o as it is the strongest model that is fine-tunable that I know of."
      ],
      "metadata": {
        "id": "qV3t9WrtpMEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "UVIhgJK-o50E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcekj3_chqzt",
        "outputId": "3b510218-e6fc-4f82-f400-4b70d9ce0dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Anthropic in /usr/local/lib/python3.12/dist-packages (0.72.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from Anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from Anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->Anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->Anthropic) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->Anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->Anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->Anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->Anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->Anthropic) (0.4.2)\n",
            "Requirement already satisfied: datasets<4 in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets<4) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<4) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets<4) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets<4) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<4) (1.17.0)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.12.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.12/dist-packages (6.0.12)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: lorem-text in /usr/local/lib/python3.12/dist-packages (3.0)\n",
            "Collecting safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements\n",
            "  Cloning https://github.com/safety-research/safety-tooling.git (to revision unpinned_requirements) to /tmp/pip-install-f4rucryf/safetytooling_36049832e8214dbba8aa0f2d2926fba4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/safety-research/safety-tooling.git /tmp/pip-install-f4rucryf/safetytooling_36049832e8214dbba8aa0f2d2926fba4\n",
            "  Running command git checkout -b unpinned_requirements --track origin/unpinned_requirements\n",
            "  Switched to a new branch 'unpinned_requirements'\n",
            "  Branch 'unpinned_requirements' set up to track remote branch 'unpinned_requirements' from 'origin'.\n",
            "  Resolved https://github.com/safety-research/safety-tooling.git to commit fa007f06b18a6f0a2b3ebd6b3bc692f216505eca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.109.1)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.72.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.122.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.8.5)\n",
            "Requirement already satisfied: together in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.5.29)\n",
            "Requirement already satisfied: elevenlabs in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.21.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.57.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.22.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.25.1)\n",
            "Requirement already satisfied: python-io in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (5.24.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.13.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.11.10)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.0.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.1.6)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (8.5.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.67.1)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.1.7)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.12.0)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (7.0.1)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.9.9)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (8.4.2)\n",
            "Requirement already satisfied: pytest-asyncio in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.2.0)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.8.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.36.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.2.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from dotenv->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.2.1)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.12/dist-packages (from elevenlabs->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (15.0.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.28.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (5.29.5)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.38.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.15.0)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.1.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.46.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.6.15)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.185.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.0.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (25.4.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2025.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.19.2)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.12/dist-packages (from pytest-xdist->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.1.1)\n",
            "Requirement already satisfied: customtkinter in /usr/local/lib/python3.12/dist-packages (from python-io->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (5.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2024.11.6)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.13.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (8.3.0)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.2.2)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.9.0)\n",
            "Requirement already satisfied: typer<0.20,>=0.9 in /usr/local/lib/python3.12/dist-packages (from together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.19.2)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.6.2)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.5.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.42.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.3->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.11)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.23)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.71.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.8.1->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20,>=0.9->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (1.5.4)\n",
            "Requirement already satisfied: darkdetect in /usr/local/lib/python3.12/dist-packages (from customtkinter->python-io->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.8.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (4.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform->safetytooling@ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install Anthropic\n",
        "%pip install \"datasets<4\"\n",
        "%pip install \"faker\"\n",
        "%pip install feedparser beautifulsoup4\n",
        "%pip install \"lorem-text\"\n",
        "%pip install \"safetytooling @ git+https://github.com/safety-research/safety-tooling.git@unpinned_requirements\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and initializations"
      ],
      "metadata": {
        "id": "EKKWI909pDo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import anthropic\n",
        "import asyncio\n",
        "import csv\n",
        "import faker\n",
        "import feedparser\n",
        "import json\n",
        "import os\n",
        "import pydantic\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import statistics\n",
        "import time\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from bs4 import BeautifulSoup\n",
        "from datasets import load_dataset\n",
        "from datetime import datetime, timezone\n",
        "from google.colab import userdata\n",
        "from lorem_text import lorem\n",
        "from pathlib import Path\n",
        "from safetytooling.apis import InferenceAPI\n",
        "from safetytooling.data_models import ChatMessage, MessageRole, Prompt, LLMResponse\n",
        "from typing import Dict, List, Optional\n",
        "from urllib.parse import quote\n",
        "\n",
        "OPENROUTER_API_KEY = userdata.get('OpenRouterKey')\n",
        "ANTHROPIC_API_KEY = userdata.get('ClaudeAPIkey')\n",
        "NUM_THREADS = 100  # Look for Error 429\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENROUTER_API_KEY # safety-tooling assumes this is set\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
        "\n",
        "claude_client = anthropic.Anthropic()\n",
        "\n",
        "API = InferenceAPI(\n",
        "    cache_dir=Path(\"/content/cache\"),\n",
        "    openrouter_num_threads=NUM_THREADS,\n",
        "    openai_num_threads=NUM_THREADS,\n",
        "#    no_cache=True,                                #for debugging\n",
        "#    openai_fraction_rate_limit=0.2,\n",
        "#    openai_base_url=\"https://openrouter.ai/api/v1\"\n",
        "    )\n",
        "\n",
        "semaphore = asyncio.Semaphore(NUM_THREADS)\n",
        "\n",
        "fake = faker.Faker()\n",
        "\n",
        "my_model_list = ['openai/gpt-4-turbo', 'openai/gpt-4o', 'openai/gpt-4o-mini', 'anthropic/claude-sonnet-4.5', 'anthropic/claude-opus-4.1']\n",
        "default_model = my_model_list[1]\n",
        "\n",
        "train_frac = 0.5  # what fraction of a dataset is for training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8npeZS7pPr1",
        "outputId": "45545770-7cc8-4384-ee5f-0189becac850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cache_dir=PosixPath('/content/cache'), use_redis=False, num_bins=20\n",
            "self.cache_manager=<safetytooling.apis.inference.cache_manager.FileBasedCacheManager object at 0x78aa85d85280>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "USnkA5JXta1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get info on models available\n",
        "models_response = requests.get(\"https://openrouter.ai/api/v1/models\")\n",
        "available_models = {m['id']: m for m in models_response.json()['data']}\n",
        "all_model_ids = list(available_models.keys())\n",
        "all_model_ids.sort()\n",
        "\n",
        "print(\"Available models:\", len(available_models))\n",
        "print(\"model attributes:\", list(available_models[all_model_ids[0]].keys()))\n",
        "\n",
        "print(\"\\nExample model IDs:\")\n",
        "for model in my_model_list:\n",
        "    print(available_models[model]['id'], available_models[model]['created'], 1_000_000 * float(available_models[model]['pricing']['prompt']), 1_000_000 * float(available_models[model]['pricing']['completion']), available_models[model]['supported_parameters'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFyx3ggwu7ne",
        "outputId": "155fbf99-6034-4373-84f5-14e52cf1c768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models: 351\n",
            "model attributes: ['id', 'canonical_slug', 'hugging_face_id', 'name', 'created', 'description', 'context_length', 'architecture', 'pricing', 'top_provider', 'per_request_limits', 'supported_parameters', 'default_parameters']\n",
            "\n",
            "Example model IDs:\n",
            "openai/gpt-4-turbo 1712620800 10.0 30.0 ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']\n",
            "openai/gpt-4o 1715558400 2.5 10.0 ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']\n",
            "openai/gpt-4o-mini 1721260800 0.15 0.6 ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']\n",
            "anthropic/claude-sonnet-4.5 1759161676 3.0 15.0 ['include_reasoning', 'max_tokens', 'reasoning', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']\n",
            "anthropic/claude-opus-4.1 1754411591 15.0 75.0 ['include_reasoning', 'max_tokens', 'reasoning', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def even_floor(n: int | float) -> int:\n",
        "    return int(2 * (n // 2))"
      ],
      "metadata": {
        "id": "n4X5CqA-b46V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def promptify(prompt: str) -> Prompt:\n",
        "    return Prompt(messages=[ChatMessage(content=prompt, role=MessageRole.user)])\n",
        "\n",
        "\n",
        "async def simple_prompt(\n",
        "    prompt: str,\n",
        "    system_prompt: str = \"\",\n",
        "    model: str = default_model,\n",
        "    max_retries: int = 5,\n",
        "    max_tokens: int = 500,\n",
        "    temperature: float = 0,\n",
        "    verbose: bool = False,\n",
        "    **kwargs\n",
        ") -> LLMResponse:\n",
        "\n",
        "    if system_prompt:\n",
        "        system_prompt = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        system_prompt = []\n",
        "\n",
        "    user_prompt = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    messages = system_prompt + user_prompt\n",
        "    prompt = Prompt(messages=messages)\n",
        "\n",
        "    async with semaphore:\n",
        "\n",
        "        responses = await API.__call__(\n",
        "            model_id=model,\n",
        "            prompt=prompt,\n",
        "            max_attempts_per_api_call=max_retries,\n",
        "#            force_provider=\"openai\" if model[:6] == \"openai\" else \"openrouter\",\n",
        "            force_provider=\"openrouter\",\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            use_cache=True, #Consider deactivating for debugging\n",
        "            extra_body={\"max_output_tokens\": 500},\n",
        "            **kwargs\n",
        "        )\n",
        "        response = responses[0]\n",
        "        if verbose:\n",
        "            print(f\"Got response from {model} after {response.duration:.2f}s\")\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "# Simple prompts\n",
        "for model_id in my_model_list:\n",
        "  response = await simple_prompt(\n",
        "      \"Dude, what is up?\",\n",
        "      model=model_id,\n",
        "      max_retries=1,\n",
        "      temperature=1.0,\n",
        "      max_tokens=200\n",
        "  )\n",
        "  print(f\"Response from {model_id}: {response.completion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvr6pLlPtcO7",
        "outputId": "5eb5a18a-6d35-40ba-f07b-cedd8f075dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from openai/gpt-4-turbo: Hello! Not much, just here to help you out. What's up with you? Anything specific you need assistance with today?\n",
            "Response from openai/gpt-4o: Not much, just here to help out! What's up with you?\n",
            "Response from openai/gpt-4o-mini: Not much! Just here and ready to help you with whatever you need. What's on your mind?\n",
            "Response from anthropic/claude-sonnet-4.5: Hey! Not much, just here and ready to chat. What's going on with you?\n",
            "Response from anthropic/claude-opus-4.1: Hey! Not much, just here chatting with you. What's going on with you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A convenience method for building a few-shot prompt to pass into an api call, as well as an example api call\n",
        "def format_few_shot_prompt(prompts_and_responses: list[tuple[str, str]]) -> list[dict]:\n",
        "  \"\"\"\n",
        "  Formats a set of few-shot examples into alternating user and assistant messages.\n",
        "\n",
        "  Args:\n",
        "    prompts_and_responses: A list of paired prompts and responses.\n",
        "  \"\"\"\n",
        "  messages = []\n",
        "  for p, r in prompts_and_responses:\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": p,\n",
        "        }\n",
        "    )\n",
        "    messages.append(\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": r\n",
        "        }\n",
        "    )\n",
        "\n",
        "  return messages\n",
        "this_fsp = format_few_shot_prompt([(\"What is 2 + 2?\", \"2 + 2 = 4.\"), (\"What is 42*23?\", \"42 * 23 = 966.\"), (\"What is 1 + 2 + 3?\", \"1 + 2 + 3 = 6.\")])\n",
        "print(f\"Few Shot Prompt Messages:\\n{this_fsp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHgsrgr4W1U",
        "outputId": "8734e9d4-9982-4368-d533-81ee7741192d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few Shot Prompt Messages:\n",
            "[{'role': 'user', 'content': 'What is 2 + 2?'}, {'role': 'assistant', 'content': '2 + 2 = 4.'}, {'role': 'user', 'content': 'What is 42*23?'}, {'role': 'assistant', 'content': '42 * 23 = 966.'}, {'role': 'user', 'content': 'What is 1 + 2 + 3?'}, {'role': 'assistant', 'content': '1 + 2 + 3 = 6.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_message_with_few_shot_prompt(\n",
        "    few_shot_prompt: list[dict],\n",
        "    prompt: str,\n",
        "    system_prompt: str ='',\n",
        "    model: str = default_model,\n",
        "    max_retries: int = 5,\n",
        "    max_tokens: int = 500,\n",
        "    temperature: float = 0,\n",
        "    verbose: bool = False,\n",
        "    **kwargs\n",
        ") -> LLMResponse:\n",
        "\n",
        "    if system_prompt:\n",
        "        system_prompt = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        system_prompt = []\n",
        "\n",
        "    user_prompt = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    messages = system_prompt + few_shot_prompt + user_prompt\n",
        "    prompt = Prompt(messages=messages)\n",
        "\n",
        "    async with semaphore:\n",
        "\n",
        "        responses = await API.__call__(\n",
        "            model_id=model,\n",
        "            prompt=prompt,\n",
        "            max_attempts_per_api_call=max_retries,\n",
        "            force_provider=\"openrouter\",\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            use_cache=True,\n",
        "            **kwargs\n",
        "        )\n",
        "        response = responses[0]\n",
        "        if verbose:\n",
        "            print(f\"Got response from {model} after {response.duration:.2f}s\")\n",
        "\n",
        "        return response\n",
        "\n",
        "system_prompt = \"You are a math expert and you solve problems.\"\n",
        "response = await get_message_with_few_shot_prompt(this_fsp, prompt=\"What is 64 ** 2?\", system_prompt=system_prompt, verbose=True)\n",
        "print(f\"Response:\\n{response}\")\n",
        "print(f\"Final text response:\\n{response.completion}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAxRE0Bu5vBt",
        "outputId": "e046908b-96be-4607-a554-7dbd699828c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got response from openai/gpt-4o after 0.80s\n",
            "Response:\n",
            "model_id='openai/gpt-4o' completion='64 squared, or 64 ** 2, is 4,096.' stop_reason=<StopReason.STOP_SEQUENCE: 'stop_sequence'> cost=0.0 audio_out=None duration=0.7993087768554688 api_duration=0.7992823123931885 logprobs=None safety_ratings=None recitation_retries=None api_failures=0 batch_custom_id=None reasoning_content=None\n",
            "Final text response:\n",
            "64 squared, or 64 ** 2, is 4,096.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_messages_with_0_shot_prompts(\n",
        "    prompts: list[str],\n",
        "    system_prompt: str='',\n",
        "    **kwargs\n",
        ") -> list[LLMResponse]:\n",
        "  messages = await asyncio.gather(\n",
        "      *[\n",
        "          simple_prompt(\n",
        "              prompt=p,\n",
        "              system_prompt=system_prompt,\n",
        "              **kwargs\n",
        "          )\n",
        "          for p in prompts\n",
        "      ]\n",
        "  )\n",
        "  return messages\n",
        "\n",
        "responses = await get_messages_with_0_shot_prompts(['Hi!  How you doing?'])#, model=my_model_list[-1])\n",
        "print(responses[0].completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msBelFo7zQ9_",
        "outputId": "43a0603f-f784-483e-de38-122bf220b80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_messages_with_few_shot_prompts(\n",
        "    few_shot_prompts: list[list[dict]] | list[list[str]],\n",
        "    prompts: list[str],\n",
        "    system_prompt: str,\n",
        "    **kwargs\n",
        ") -> list[LLMResponse]:\n",
        "  messages = await asyncio.gather(\n",
        "      *[\n",
        "          get_message_with_few_shot_prompt(\n",
        "              fsp,\n",
        "              prompt=p,\n",
        "              system_prompt=system_prompt,\n",
        "              **kwargs\n",
        "          )\n",
        "          for fsp, p in zip(few_shot_prompts, prompts)\n",
        "      ]\n",
        "  )\n",
        "  return messages"
      ],
      "metadata": {
        "id": "9K0RmBeCzAme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_messages_with_single_few_shot_prompt(\n",
        "    few_shot_prompt: list[dict] | list[str],\n",
        "    prompts: list[str],\n",
        "    system_prompt: str,\n",
        "    **kwargs\n",
        ") -> list[LLMResponse]:\n",
        "  messages = await asyncio.gather(\n",
        "      *[\n",
        "          get_message_with_few_shot_prompt(\n",
        "              few_shot_prompt,\n",
        "              prompt=p,\n",
        "              system_prompt=system_prompt,\n",
        "              **kwargs\n",
        "          )\n",
        "          for p in prompts\n",
        "      ]\n",
        "  )\n",
        "  return messages"
      ],
      "metadata": {
        "id": "waMDNHTfK-0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Force boolean out using second call to Sonnet.  Seems something in the safetytooling/OpenRouter/Anthropic chain doesn't play nice with tool use, so just using Anthropic API directly\n",
        "async def boole_force(\n",
        "    orig_prompt: str,\n",
        "    init_response: str,\n",
        "    system_prompt: str = \"You are are a Boolean knowledge engine: You respond as accurately as possible to prompts.  Respond only in 'True' and 'False'.\",\n",
        "    max_retries: int = 4,\n",
        "    max_tokens: int = 2000,  # Won't hit it unless input gets clipped\n",
        "    temperature: float = 0,\n",
        "    verbose: bool = False,\n",
        "    **kwargs\n",
        "    ) -> str:\n",
        "\n",
        "    async with semaphore:\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                final_response = claude_client.messages.create(\n",
        "                    model='claude-sonnet-4-5',\n",
        "                    max_tokens=max_tokens,\n",
        "                    tools=[{\n",
        "                        \"name\": \"submit_classification\",\n",
        "                        \"description\": \"Submit the final boolean classification\",\n",
        "                        \"input_schema\": {\n",
        "                            \"type\": \"object\",\n",
        "                            \"properties\": {\n",
        "                                \"result\": {\n",
        "                                    \"type\": \"string\",\n",
        "                                    \"enum\": [\"True\", \"False\"],\n",
        "                                    \"description\": \"The classification result\"\n",
        "                                }\n",
        "                            },\n",
        "                            \"required\": [\"result\"]\n",
        "                        }\n",
        "                    }],\n",
        "                    tool_choice={\"type\": \"tool\", \"name\": \"submit_classification\"},\n",
        "                    system=[\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": system_prompt\n",
        "                        }\n",
        "                    ],\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": orig_prompt},\n",
        "                        {\"role\": \"assistant\", \"content\": init_response.strip()} # Strip trailing whitespace here\n",
        "                    ]\n",
        "                )\n",
        "                return final_response.content[0].input['result']\n",
        "            except anthropic.InternalServerError as e:\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Attempt {attempt + 1} failed: {e}. Retrying...\")\n",
        "                    await asyncio.sleep(2 ** attempt)  # Exponential backoff\n",
        "                else:\n",
        "                    raise # Re-raise the exception after max retries\n",
        "        return \"\" # Should not reach here, but for type hinting"
      ],
      "metadata": {
        "id": "24UrB_t9fn9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "UJ5Abxk7OxE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case data (\"Careful Garbage\")"
      ],
      "metadata": {
        "id": "g9gDJiNMmRPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate careful garbage sentences in all-lower and not\n",
        "garbage_case_data = []\n",
        "for i in range(500):\n",
        "    sentence_length = random.randint(4, 6)\n",
        "    some_words = fake.words(sentence_length)\n",
        "    lower_sentence = ' '.join(some_words)\n",
        "    for j in random.sample(list(range(sentence_length)), random.randint(1, sentence_length)):\n",
        "        some_words[j] = some_words[j].upper()\n",
        "    UPPER_sentence = ' '.join(some_words)\n",
        "    output = [(lower_sentence, 'True'), (UPPER_sentence, 'False')]\n",
        "    if random.getrandbits(1):\n",
        "        output = output[::-1]\n",
        "    garbage_case_data += output\n",
        "\n",
        "garbage_case_train = garbage_case_data[:10]\n",
        "garbage_case_test = random.sample(garbage_case_data[10:], 990)\n",
        "for datum in garbage_case_train:\n",
        "    print(datum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96iw5lSTGIxQ",
        "outputId": "665c6b17-dbf9-44d4-ac47-6b6164ab3d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('price BECOME task FIRM', 'False')\n",
            "('price become task firm', 'True')\n",
            "('PAINTING ROAD line time LOCAL ball', 'False')\n",
            "('painting road line time local ball', 'True')\n",
            "('SPEECH table where test RECENT', 'False')\n",
            "('speech table where test recent', 'True')\n",
            "('matter on simple book debate kitchen', 'True')\n",
            "('MATTER ON simple BOOK DEBATE KITCHEN', 'False')\n",
            "('around rate operation say technology development', 'True')\n",
            "('around rate operation say TECHNOLOGY DEVELOPMENT', 'False')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## News paragraphs\n",
        "Of major outlets that provide RSS freely, Fox News and The Guardian seem to be the most divergent in reportage."
      ],
      "metadata": {
        "id": "cYveuBKamcbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Collect one paragraph from up to 55 recent items from The Guardian and Fox News via OFFICIAL RSS ONLY.\n",
        "Intended for private/internal analysis. Always review & follow each provider's terms.\n",
        "- Attribution kept (title, outlet, canonical URL).\n",
        "- No paywalled HTML or bulk article scraping; RSS summaries only.\n",
        "- Polite User-Agent and minimal requests.\n",
        "\"\"\"\n",
        "\n",
        "news_data = []\n",
        "\n",
        "# ---- CONFIG ----\n",
        "USER_AGENT = \"NewsParagraphCollector/1.0\"\n",
        "MAX_PER_SOURCE = 55\n",
        "RATE_LIMIT_SECONDS = 2  # courtesy gap between sources (RSS calls are cheap; still be polite)\n",
        "\n",
        "# --- replace your SOURCES with this ---\n",
        "SOURCES = [\n",
        "    {\n",
        "        \"name\": \"The Guardian\",\n",
        "        \"feeds\": [\"https://www.theguardian.com/international/rss\"],\n",
        "        \"skip_title_patterns\": [r\"\\blive\\b\", r\"\\blive blog\\b\", r\"\\bvideo\\b\"],\n",
        "        \"skip_category_patterns\": [r\"\\bVideo\\b\", r\"\\bLive\\b\", r\"\\bLive blog\\b\"],\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Fox News\",\n",
        "        \"feeds\": [\n",
        "            \"https://feeds.foxnews.com/foxnews/latest\",\n",
        "            \"https://feeds.foxnews.com/foxnews/politics\",\n",
        "            \"https://feeds.foxnews.com/foxnews/us\",\n",
        "            \"https://feeds.foxnews.com/foxnews/world\",\n",
        "        ],\n",
        "        \"skip_title_patterns\": [r\"\\bvideo\\b\", r\"\\blive\\b\"],\n",
        "        \"skip_category_patterns\": [r\"\\bVideo\\b\", r\"\\bLive\\b\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def first_paragraph_from_html(html_snippet: str) -> str:\n",
        "    \"\"\"Find the first non-empty paragraph from an HTML snippet.\"\"\"\n",
        "    soup = BeautifulSoup(html_snippet or \"\", \"html.parser\")\n",
        "\n",
        "    # Prefer real <p> elements\n",
        "    for p in soup.find_all(\"p\"):\n",
        "        text = p.get_text(\" \", strip=True)\n",
        "        if text:\n",
        "            return text\n",
        "\n",
        "    # Fallback: strip tags; use first non-empty chunk split by blank lines\n",
        "    plain = soup.get_text(\"\\n\", strip=True)\n",
        "    for chunk in re.split(r\"\\n{2,}\", plain):\n",
        "        chunk = chunk.strip()\n",
        "        if chunk:\n",
        "            return chunk\n",
        "\n",
        "    return plain.strip()\n",
        "\n",
        "\n",
        "def _compiled(patterns: List[str]) -> List[re.Pattern]:\n",
        "    return [re.compile(pat, flags=re.IGNORECASE) for pat in patterns]\n",
        "\n",
        "\n",
        "def looks_like_non_article(entry, title_skips: List[re.Pattern], category_skips: List[re.Pattern]) -> bool:\n",
        "    title = (entry.get(\"title\") or \"\").strip()\n",
        "    if any(p.search(title) for p in title_skips):\n",
        "        return True\n",
        "\n",
        "    # Check categories/tags when present\n",
        "    for tag in entry.get(\"tags\", []) or []:\n",
        "        cat = (tag.get(\"term\") or \"\").strip()\n",
        "        if any(p.search(cat) for p in category_skips):\n",
        "            return True\n",
        "\n",
        "    # Some feeds include podcasts/videos with enclosures only\n",
        "    if entry.get(\"enclosures\"):\n",
        "        # If there's an enclosure but no textual summary/content, likely non-article\n",
        "        if not entry.get(\"summary\") and not entry.get(\"content\"):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def parse_published(entry) -> Optional[str]:\n",
        "    # Try multiple fields; return ISO 8601\n",
        "    if \"published_parsed\" in entry and entry.published_parsed:\n",
        "        dt = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)\n",
        "        return dt.isoformat()\n",
        "    if \"updated_parsed\" in entry and entry.updated_parsed:\n",
        "        dt = datetime(*entry.updated_parsed[:6], tzinfo=timezone.utc)\n",
        "        return dt.isoformat()\n",
        "    if \"published\" in entry:\n",
        "        return entry[\"published\"]\n",
        "    if \"updated\" in entry:\n",
        "        return entry[\"updated\"]\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_paragraph_from_entry(entry) -> Optional[str]:\n",
        "    # Prefer summary or content from RSS\n",
        "    html_snippet = (\n",
        "        entry.get(\"summary\")\n",
        "        or (entry.get(\"description\") or \"\")\n",
        "        or ((entry.get(\"content\") or [{}])[0].get(\"value\") or \"\")\n",
        "    )\n",
        "    para = first_paragraph_from_html(html_snippet)\n",
        "    # Require a little substance to avoid 1–2 word stubs\n",
        "    if para and len(para.split()) >= 5:\n",
        "        return para\n",
        "    return None\n",
        "\n",
        "\n",
        "def collect_from_source(source: dict) -> list[dict]:\n",
        "    name = source[\"name\"]\n",
        "    feeds = source[\"feeds\"]\n",
        "    title_skips = _compiled(source.get(\"skip_title_patterns\", []))\n",
        "    category_skips = _compiled(source.get(\"skip_category_patterns\", []))\n",
        "\n",
        "    records, seen_links = [], set()\n",
        "\n",
        "    for feed_url in feeds:\n",
        "        feed = feedparser.parse(feed_url, request_headers={\"User-Agent\": USER_AGENT})\n",
        "        entries = feed.entries or []\n",
        "\n",
        "        for entry in entries:\n",
        "            if len(records) >= MAX_PER_SOURCE:\n",
        "                break\n",
        "\n",
        "            if looks_like_non_article(entry, title_skips, category_skips):\n",
        "                continue\n",
        "\n",
        "            link = (entry.get(\"link\") or \"\").strip()\n",
        "            title = (entry.get(\"title\") or \"\").strip()\n",
        "            if not link or link in seen_links:\n",
        "                continue\n",
        "\n",
        "            para = extract_paragraph_from_entry(entry)\n",
        "            if not para:\n",
        "                continue\n",
        "\n",
        "            seen_links.add(link)\n",
        "            records.append({\n",
        "                \"source\": name,\n",
        "                \"feed_url\": feed_url,\n",
        "                \"title\": title,\n",
        "                \"link\": link,\n",
        "                \"published\": parse_published(entry),\n",
        "                \"paragraph\": para,\n",
        "            })\n",
        "\n",
        "        if len(records) >= MAX_PER_SOURCE:\n",
        "            break\n",
        "\n",
        "        time.sleep(1)  # tiny courtesy pause between feeds of the same source\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "def save_csv(path: str, rows: List[Dict]) -> None:\n",
        "    if not rows:\n",
        "        return\n",
        "    fieldnames = [\"source\", \"feed_url\", \"title\", \"link\", \"published\", \"paragraph\"]\n",
        "    with open(path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for r in rows:\n",
        "            writer.writerow(r)\n",
        "\n",
        "\n",
        "def save_jsonl(path: str, rows: List[Dict]) -> None:\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "def collate_data(rows: List[Dict]) -> None:\n",
        "    for r in rows:\n",
        "        news_data.append((r[\"paragraph\"], str(r[\"source\"] == SOURCES[0][\"name\"])))\n",
        "\n",
        "\n",
        "def collect_news_data():\n",
        "    all_rows: List[Dict] = []\n",
        "\n",
        "    for i, src in enumerate(SOURCES):\n",
        "        rows = collect_from_source(src)\n",
        "        all_rows.extend(rows)\n",
        "        if i < len(SOURCES) - 1:\n",
        "            time.sleep(RATE_LIMIT_SECONDS)  # courteous pause between sources\n",
        "\n",
        "    # Timestamped filenames\n",
        "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "    csv_path = f\"news_paragraphs_{ts}.csv\"\n",
        "    jsonl_path = f\"news_paragraphs_{ts}.jsonl\"\n",
        "\n",
        "    save_csv(csv_path, all_rows)\n",
        "    save_jsonl(jsonl_path, all_rows)\n",
        "    collate_data(all_rows)\n",
        "\n",
        "    print(f\"Collected {len(all_rows)} paragraphs total.\")\n",
        "    by_src = {}\n",
        "    for r in all_rows:\n",
        "        by_src[r[\"source\"]] = by_src.get(r[\"source\"], 0) + 1\n",
        "    for src, n in by_src.items():\n",
        "        print(f\"  {src}: {n}\")\n",
        "\n",
        "    print(f\"\\nSaved:\\n  CSV   => {csv_path}\\n  JSONL => {jsonl_path}\")\n",
        "    print(\"\\nNotes:\")\n",
        "    print(\"- Uses official RSS only; keeps attribution (title, source, URL).\")\n",
        "    print(\"- Intended for private/internal analysis; avoid republishing the text.\")\n",
        "    print(\"- User-Agent set to an honest identifier; consider adding a contact URL/email.\")"
      ],
      "metadata": {
        "id": "0axv57ogmpar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collect_news_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnArAdksn_39",
        "outputId": "795407b3-99c0-4313-e874-a5a283b45212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected 110 paragraphs total.\n",
            "  The Guardian: 55\n",
            "  Fox News: 55\n",
            "\n",
            "Saved:\n",
            "  CSV   => news_paragraphs_20251031T080306Z.csv\n",
            "  JSONL => news_paragraphs_20251031T080306Z.jsonl\n",
            "\n",
            "Notes:\n",
            "- Uses official RSS only; keeps attribution (title, source, URL).\n",
            "- Intended for private/internal analysis; avoid republishing the text.\n",
            "- User-Agent set to an honest identifier; consider adding a contact URL/email.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_train = random.sample(news_data[:5] + news_data[-5:], 10)\n",
        "news_test = news_data[5:-5]\n",
        "for item in news_train:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMkOQaZ8uU5w",
        "outputId": "2dca3fbc-c39a-4838-fcc9-cc0bad411553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Putin announced successful Poseidon nuclear drone testing as President Donald Trump urged Russia to end the Ukraine war instead of testing missiles on Monday.', 'False')\n",
            "('An 80-year-old Australian woman was found dead after the Coral Adventurer cruise ship allegedly left her behind on Lizard Island during a hiking tour.', 'False')\n",
            "('Forget the Monster Mash. For the ultimate Halloween playlist, reach for horror soundtracks, 1940s kids’ music and Russian darkwave – all chosen by Sunn O))), Creeper, Diamanda Galás and more', 'True')\n",
            "('In California, daily life under Trump is marked by sporadic resistance and avoidance. Neither will defeat the autocrats', 'True')\n",
            "('Tarek Bazrouk, a 20-year-old Palestinian American, was sentenced to 17 months in prison for federal hate crimes after attacking Jewish protesters in New York City.', 'False')\n",
            "('Trump announced a cut on Chinese imports after meeting with Xi in South Korea, citing new understandings on fentanyl enforcement, farm trade and rare-earth exports.', 'False')\n",
            "('The U.S. military targeted another alleged narco-trafficking boat, sparking congressional concerns over due process and legal authority for the deadly strikes.', 'False')\n",
            "('Jettisoning of ex-prince became unavoidable when king’s loyalty to his brother collided with task of keeping public on side', 'True')\n",
            "('The man was unconscious but there was no time to wake him, the smoke and flames were closing in', 'True')\n",
            "('(Polydor) On her self-deprecating, viscera-flecked sixth record, Florence Welch picks apart the compulsions and contradictions of fame', 'True')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arithmetic sequences"
      ],
      "metadata": {
        "id": "VgNRVR0N07re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data = []\n",
        "for i in range(110):\n",
        "    truth = bool(i % 2)\n",
        "    if truth:\n",
        "        step_size = random.randint(1, 100)\n",
        "        start = random.randint(1, 1000 - 8 * step_size)\n",
        "        sequence = list(range(start, start + 8 * step_size, step_size))\n",
        "    else:\n",
        "        sequence = sorted([random.randint(1, 1000) for _ in range(8)])\n",
        "    sequence = map(str, sequence)\n",
        "    sequence_data.append((', '.join(sequence), str(truth)))\n",
        "\n",
        "sequence_train = random.sample(sequence_data[:10], 10)\n",
        "sequence_test = random.sample(sequence_data[10:], 100)"
      ],
      "metadata": {
        "id": "pl49XDjm1AQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in sequence_train:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrkZqoZf3KDC",
        "outputId": "f016442a-19d8-42a8-88ef-6e338c7e6886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('135, 215, 239, 303, 309, 588, 647, 760', 'False')\n",
            "('291, 299, 307, 315, 323, 331, 339, 347', 'True')\n",
            "('89, 188, 287, 386, 485, 584, 683, 782', 'True')\n",
            "('80, 179, 278, 377, 476, 575, 674, 773', 'True')\n",
            "('63, 260, 372, 418, 578, 889, 901, 994', 'False')\n",
            "('293, 357, 421, 485, 549, 613, 677, 741', 'True')\n",
            "('168, 190, 436, 441, 797, 862, 956, 963', 'False')\n",
            "('134, 223, 312, 401, 490, 579, 668, 757', 'True')\n",
            "('112, 119, 141, 225, 523, 737, 853, 990', 'False')\n",
            "('147, 169, 240, 594, 660, 704, 711, 883', 'False')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Short chess games\n",
        "I got some 16-move checkmates, and the first 16 moves of some longer short games from lichess.  I removed the checkmate symbols."
      ],
      "metadata": {
        "id": "qqoyxEQNQeC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chess_mates = ['1. b3 e5 2. Bb2 e4 3. d3 Nf6 4. Nh3 d5 5. dxe4 Nxe4 6. Nf4 Qh4 7. g3 Bc5 8. f3 Bf2', '1. e4 e5 2. Bc4 Nf6 3. d3 d5 4. exd5 Bc5 5. h3 e4 6. Bg5 h6 7. Bxf6 Qxf6 8. dxe4 Qxf2', '1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qg5 6. O-O Qxe5 7. Nc3 Bd6 8. d4 Qxh2', '1. f4 e5 2. fxe5 f6 3. e4 fxe5 4. d3 Qf6 5. Nf3 Bc5 6. Nbd2 g5 7. Be2 g4 8. Ng5 Qf2', '1. d3 e5 2. Kd2 Bc5 3. Kc3 d5 4. Kb3 d4 5. Kc4 b6 6. e3 Be6+ 7. Kb5 c6+ 8. Ka4 b5', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nd4 4. Nxe5 Qg5 5. Bxf7+ Ke7 6. Na3 Qxg2 7. Rf1 Qxe4+ 8. Qe2 Qxe2', '1. c4 e5 2. e4 c6 3. Nc3 Nf6 4. h3 d5 5. Nf3 dxe4 6. Nxe5 Bc5 7. Be2 Qd4 8. Nxf7 Qxf2', '1. e4 e5 2. Nf3 Nc6 3. Bb5 d6 4. Bxc6+ bxc6 5. d4 Bg4 6. dxe5 dxe5 7. Qxd8+ Rxd8 8. Nxe5 Rd1', '1. e4 e5 2. Nf3 d6 3. d4 f6 4. dxe5 fxe5 5. Bc4 Nf6 6. Ng5 Nxe4 7. Nf7 Qf6 8. Nxh8 Qxf2', '1. e4 d5 2. f3 dxe4 3. Qe2 exf3 4. Kd1 fxe2+ 5. Bxe2 Qd3 6. Nf3 Qxf3 7. Ke1 Bg4 8. b3 Qxe2', '1. e4 e5 2. Bc4 Bc5 3. Nf3 d6 4. d3 Bb6 5. Ng5 Be6 6. Bxe6 fxe6 7. Nxe6 Qf6 8. Ng5 Qxf2', '1. e4 e5 2. Nf3 Nc6 3. Nc3 Bc5 4. Nxe5 Nxe5 5. Nd5 c6 6. Nf4 Qf6 7. d3 d6 8. Nh5 Qxf2', '1. e4 e5 2. Nf3 Qf6 3. b3 Nh6 4. d4 exd4 5. Nxd4 Bb4+ 6. c3 Bc5 7. b4 Bb6 8. Nb5 Qxf2', '1. d4 e5 2. dxe5 Nc6 3. Nf3 Qe7 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd3 Bxc3+ 8. Qxc3 Qc1', '1. e4 e5 2. Nf3 Nf6 3. Nc3 d5 4. exd5 e4 5. Nd4 c5 6. dxc6 Qxd4 7. d3 Bc5 8. c7 Qxf2', '1. e4 c6 2. d4 d6 3. Bc4 Nf6 4. Qf3 Bg4 5. Qf4 Nbd7 6. e5 dxe5 7. dxe5 Nxe5 8. Qxe5 Qd1', '1. c3 c5 2. d4 d5 3. dxc5 Nc6 4. b4 d4 5. c4 Nf6 6. b5 Nb4 7. a3 Qa5 8. Bb2 Nc2', '1. e4 e5 2. Nc3 Bc5 3. Bc4 Nc6 4. f3 h6 5. Nge2 d6 6. a3 a6 7. d3 Qh4+ 8. Kf1 Qf2', '1. d4 Nf6 2. e3 e6 3. Bd3 c5 4. Ne2 d5 5. O-O c4 6. Bxh7 Rxh7 7. b3 Qc7 8. bxc4 Qxh2', '1. e3 e6 2. Nf3 c5 3. Nc3 Nc6 4. d4 d5 5. dxc5 Bxc5 6. e4 Qb6 7. e5 Bxf2+ 8. Kd2 Qe3', '1. e4 e5 2. Bc4 Nf6 3. Nf3 Nxe4 4. Nxe5 Qe7 5. Qf3 Qxe5 6. Qxf7+ Kd8 7. O-O Bd6 8. d3 Qxh2', '1. d4 e5 2. dxe5 Nc6 3. Nf3 Qe7 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd2 Bxc3 8. Qxc3 Qc1', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nd4 4. Nxe5 Qg5 5. Bxf7+ Ke7 6. Bxg8 Qxg2 7. Rf1 Qxe4+ 8. Qe2 Qxe2', '1. e4 d5 2. e5 Nh6 3. Qf3 Bg4 4. Qf4 e6 5. d4 f6 6. exf6 Qxf6 7. Qxc7 Qxd4 8. Qxb7 Qd1', '1. e4 e5 2. b3 Nc6 3. Bb2 Nf6 4. Bd3 d6 5. Bb5 Nxe4 6. Bxc6+ bxc6 7. d4 Qf6 8. dxe5 Qxf2', '1. d4 g6 2. e3 Bg7 3. Bd3 e6 4. Nf3 b6 5. Ne5 Bxe5 6. dxe5 Bb7 7. O-O Qg5 8. h3 Qxg2', '1. e4 e5 2. Nf3 Nf6 3. Nxe5 d6 4. Nxf7 Kxf7 5. Bc4+ Be6 6. e5 Bxc4 7. exf6 Qe8+ 8. Qe2 Qxe2', '1. e4 e5 2. Nf3 Nc6 3. Bb5 Bd6 4. Bxc6 dxc6 5. d4 Bg4 6. dxe5 Bxe5 7. Qxd8+ Rxd8 8. Nxe5 Rd1', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Ng5 Bc5 5. Nxf7 Bxf2+ 6. Kxf2 Nxe4+ 7. Kf1 Qf6+ 8. Kg1 Qf2', '1. e4 e5 2. f4 Nc6 3. Nf3 exf4 4. Bc4 Bc5 5. d4 Nxd4 6. Nxd4 Qh4+ 7. Kf1 Nf6 8. Nf3 Qf2', '1. d4 d5 2. e3 Bf5 3. Bd3 e6 4. Nf3 Nf6 5. O-O Bg6 6. Ne5 Qd6 7. Nxg6 hxg6 8. Nc3 Qxh2', '1. d4 e5 2. dxe5 Qe7 3. Nf3 Nc6 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd3 Bxc3+ 8. Qxc3 Qc1', '1. e4 e5 2. Nf3 Bc5 3. c3 Bxf2+ 4. Kxf2 Nf6 5. Be2 Nxe4+ 6. Ke3 c6 7. Kxe4 d5+ 8. Kxe5 Qf6', '1. g3 e5 2. Bg2 d6 3. b3 Bf5 4. Bb2 Nf6 5. Bxb7 Ne4 6. Bxa8 c6 7. Nf3 Qb6 8. Nc3 Qxf2', '1. e4 e5 2. g3 d6 3. Nf3 Nf6 4. Nh4 Bg4 5. f3 Nxe4 6. fxg4 c6 7. Bc4 Qb6 8. Nf3 Qf2', '1. d4 e5 2. dxe5 Nc6 3. Nf3 Qe7 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd3 Bxc3+ 8. Qxc3 Qc1', '1. e4 e5 2. Nf3 Nf6 3. Bc4 Nc6 4. Ng5 Bc5 5. Nxf7 Bxf2+ 6. Kxf2 Nxe4+ 7. Kg1 Qf6 8. Nxh8 Qf2', '1. e4 e5 2. Nf3 d6 3. d4 Nf6 4. dxe5 Nxe4 5. exd6 Bxd6 6. Bd3 Bf5 7. Nh4 Qxh4 8. g4 Qxf2', '1. d4 e5 2. Nf3 Nc6 3. dxe5 Qe7 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd2 Bxc3 8. Qxc3 Qc1', '1. e4 e5 2. Qh5 Nc6 3. Bb5 Nf6 4. Qf3 d5 5. Bxc6+ bxc6 6. d3 Bg4 7. Qg3 dxe4 8. dxe4 Qd1', '1. d4 e5 2. dxe5 Nc6 3. Nf3 Qe7 4. Bf4 Qb4+ 5. Qd2 Qxb2 6. Qc3 Bb4 7. Bd2 Bxc3 8. Bxc3 Qc1', '1. g3 d5 2. Bg2 e5 3. d3 e4 4. dxe4 Nf6 5. exd5 Bc5 6. d6 Ng4 7. dxc7 Bxf2+ 8. Kf1 Qxd1', '1. d4 Nf6 2. c4 e5 3. dxe5 Ng4 4. Bf4 Nc6 5. Nf3 Bb4+ 6. Nbd2 Qe7 7. a3 Ngxe5 8. axb4 Nd3', '1. e4 Nc6 2. f4 e5 3. fxe5 Qh4+ 4. Ke2 Qxe4+ 5. Kf2 Bc5+ 6. Kg3 Qxe5+ 7. Kf3 Qf5+ 8. Ke2 Qe4', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nd4 4. Ng5 Qxg5 5. c3 Qxg2 6. Qh5 Qxe4+ 7. Kd1 Qxh1+ 8. Bf1 Qxf1', '1. e4 e5 2. Bc4 c6 3. Nf3 b5 4. Bb3 Nf6 5. Nxe5 Nxe4 6. Nxf7 Qh4 7. g3 Qf6 8. d3 Qxf2', '1. d4 d5 2. c4 e5 3. dxe5 d4 4. Nf3 Nc6 5. a3 Bg4 6. Nbd2 Qe7 7. g3 Nxe5 8. Nxd4 Nd3', '1. e4 e5 2. Nf3 Nc6 3. d4 exd4 4. Nxd4 Qf6 5. Be3 Bc5 6. c3 Nge7 7. Nxc6 Bxe3 8. Nxe7 Qxf2', '1. e4 e5 2. Nc3 Nc6 3. Bc4 Nf6 4. d3 Bc5 5. f4 d6 6. fxe5 dxe5 7. Bg5 Qd4 8. Bxf6 Qf2', '1. e4 e6 2. Nf3 d5 3. Bb5+ c6 4. Ba4 dxe4 5. Ne5 Qd4 6. d3 Qxe5 7. O-O Bd6 8. Nc3 Qxh2', '1. d4 Nf6 2. c4 e5 3. dxe5 Ng4 4. Bf4 Nc6 5. Nf3 Bb4+ 6. Nbd2 Qe7 7. h3 Ncxe5 8. hxg4 Nd3', '1. d4 Nf6 2. Na3 e6 3. e4 Nxe4 4. Be3 Bd6 5. b3 Bb4+ 6. Bd2 Bxd2+ 7. Ke2 Qg5 8. f3 Qe3', '1. g4 e5 2. Nf3 e4 3. Nd4 c5 4. Nb3 d5 5. Nxc5 Bxc5 6. Bg2 Bxg4 7. h3 Qf6 8. hxg4 Qxf2', '1. e4 e5 2. Nf3 Nf6 3. Bc4 d5 4. exd5 Nxd5 5. Nxe5 Be6 6. O-O Qg5 7. Bxd5 Bxd5 8. Re1 Qxg2', '1. d4 d5 2. Nc3 Nf6 3. f3 Nc6 4. e4 dxe4 5. fxe4 Qxd4 6. Be3 Qxe3+ 7. Be2 Nxe4 8. Nd5 Qf2', '1. d4 Nf6 2. c4 e5 3. dxe5 Ng4 4. Nf3 Nc6 5. Bf4 Bb4+ 6. Nbd2 Qe7 7. a3 Ngxe5 8. axb4 Nd3', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Ng5 Bc5 5. Nxf7 Bxf2+ 6. Kxf2 Nxe4+ 7. Ke1 Qh4+ 8. Kf1 Qf2', '1. e4 e5 2. Nf3 Qf6 3. d4 exd4 4. Nxd4 Bc5 5. Be3 d6 6. Bd3 Nh6 7. Bxh6 Bxd4 8. c3 Qxf2', '1. d4 e5 2. dxe5 Qe7 3. Nf3 Nc6 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd2 Bxc3 8. Qxc3 Qc1', '1. e4 e5 2. Ne2 Nf6 3. d3 Bc5 4. Bg5 Bxf2+ 5. Kxf2 Ng4+ 6. Kg1 Qxg5 7. Qe1 Qe3+ 8. Qf2 Qxf2', '1. c4 e5 2. g3 Qf6 3. Nf3 e4 4. Nh4 Bc5 5. e3 Nh6 6. Bg2 d6 7. Bxe4 Ng4 8. Nc3 Qxf2', '1. e4 e6 2. f3 f6 3. Ne2 f5 4. d3 fxe4 5. fxe4 Qh4+ 6. g3 Qf6 7. Nd2 Bc5 8. b3 Qf2', '1. e4 e5 2. f4 d5 3. exd5 Qxd5 4. Nf3 e4 5. Nc3 Qf5 6. Nd4 Qxf4 7. d3 e3 8. Nde2 Qf2', '1. d4 Nf6 2. f3 d5 3. e3 Nc6 4. g4 e5 5. c3 e4 6. fxe4 Bxg4 7. Qb3 Nxe4 8. Qxb7 Qh4', '1. e4 e5 2. f3 Nc6 3. Nc3 Bc5 4. Nge2 Qh4+ 5. g3 Qf6 6. d3 Qxf3 7. Rg1 Qf2+ 8. Kd2 Be3', '1. e4 e5 2. Nf3 d6 3. Bc4 Bg4 4. Nc3 c6 5. h3 Nf6 6. hxg4 Nxg4 7. d3 Qb6 8. Ng5 Qxf2', '1. d4 e5 2. dxe5 Nc6 3. Nf3 Qe7 4. Bf4 Qb4+ 5. Bd2 Qxb2 6. Bc3 Bb4 7. Qd4 Nxd4 8. Nxd4 Qc1']\n",
        "chess_ongoing = ['1. d4 c5 2. Nf3 cxd4 3. Nxd4 g6 4. Nc3 Bg7 5. e4 Bxd4 6. Qxd4 Nc6 7. Qxh8 Kf8 8. Bh6+ Ke8', '1. d4 d5 2. Nc3 e6 3. a3 Nf6 4. Bg5 Be7 5. e3 O-O 6. h4 Ne4 7. Qd3 Nxg5 8. hxg5 Bxg5', '1. e4 e5 2. Nf3 d6 3. Bc4 Nf6 4. Ng5 d5 5. exd5 Nxd5 6. Nxf7 Kxf7 7. Qf3+ Ke8 8. Bxd5 c6', '1. e4 e5 2. Nf3 Nc6 3. Bb5 Nf6 4. Nc3 d6 5. O-O Ng4 6. h3 h5 7. hxg4 hxg4 8. Nh2 Qh4', '1. e4 e5 2. Nf3 d6 3. Bc4 h6 4. O-O f5 5. d4 fxe4 6. Nxe5 dxe5 7. Qh5+ Ke7 8. Qxe5+ Kd7', '1. e4 e5 2. Nf3 Bc5 3. Bc4 c6 4. d3 d5 5. Bb3 dxe4 6. Ng5 Nh6 7. O-O exd3 8. Qf3 Bg4', '1. e4 e5 2. d3 h6 3. f4 exf4 4. Bxf4 d6 5. Nf3 Nc6 6. Nbd2 Bg4 7. c4 Nd4 8. h3 Bxf3', '1. e4 e5 2. Bc4 Nc6 3. Nc3 a6 4. Qf3 Qf6 5. d3 Na5 6. Nd5 Qd8 7. Nxc7+ Qxc7 8. Qxf7+ Kd8', '1. e4 e5 2. Nf3 f6 3. Bc4 h6 4. d4 exd4 5. Nxd4 a6 6. O-O b5 7. Bb3 Bb7 8. Re1 Nc6', '1. d4 Nf6 2. Bf4 e6 3. Nf3 Nc6 4. h3 d5 5. e3 Bd6 6. Bh2 O-O 7. a3 Ne4 8. Nbd2 Qf6', '1. e4 e5 2. d4 exd4 3. Qxd4 Nc6 4. Qd1 Bb4+ 5. c3 Bc5 6. b4 Bb6 7. c4 a6 8. b5 axb5', '1. e4 d5 2. exd5 Qxd5 3. Nc3 Qe6+ 4. Be2 Nc6 5. Nf3 Nh6 6. O-O Ne5 7. d3 Neg4 8. Nd4 Qd6', '1. e4 e5 2. Nf3 Nf6 3. d4 d5 4. dxe5 Nc6 5. exf6 Qxf6 6. exd5 Nb8 7. Bg5 Qf5 8. Qd3 g6', '1. d3 e5 2. e4 Nf6 3. f4 d5 4. fxe5 Nfd7 5. d4 dxe4 6. Qe2 Nc6 7. Qxe4 Be7 8. c3 O-O', '1. e4 c5 2. Nf3 Nc6 3. Bb5 Nd4 4. Nxd4 cxd4 5. O-O e5 6. f4 a6 7. Bc4 d6 8. fxe5 dxe5', '1. e4 e5 2. Nf3 Nc6 3. Nc3 Bc5 4. Nxe5 Nxe5 5. d4 Bxd4 6. Qxd4 d6 7. Bf4 f6 8. Bc4 Bd7', '1. e4 f6 2. d4 d5 3. e5 f5 4. Nf3 h6 5. Nh4 e6 6. Ng6 Rh7 7. Qh5 Kf7 8. Nh8+ Ke7', '1. d4 d5 2. c4 e5 3. dxe5 d4 4. Nf3 Nc6 5. a3 Bg4 6. e3 dxe3 7. Qxd8+ Rxd8 8. Bxe3 Nxe5', '1. c4 d5 2. Nc3 e6 3. e4 d4 4. Nce2 e5 5. f4 Bg4 6. h3 Bh5 7. g4 Qh4+ 8. Ng3 Qxg3+', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Ng5 d5 5. exd5 Nxd5 6. Nxf7 Kxf7 7. Qf3+ Ke8 8. Bxd5 Nd4', '1. e4 e5 2. Bc4 Nf6 3. Nf3 Nc6 4. Ng5 d5 5. exd5 Nd4 6. d6 Qxd6 7. Nxf7 Qc6 8. b3 Qxg2', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nh6 4. h3 Be7 5. d4 exd4 6. Nxd4 d6 7. Nxc6 bxc6 8. Bxh6 gxh6', '1. d4 d5 2. c4 Nc6 3. c5 e5 4. e3 Nf6 5. dxe5 Nxe5 6. e4 Bxc5 7. exd5 O-O 8. Bg5 Re8', '1. e4 e5 2. Qh5 Nh6 3. Qxe5+ Be7 4. Qxg7 Rg8 5. Qxh6 b5 6. Qxh7 Bb7 7. Qxg8+ Bf8 8. d3 Bxe4', '1. e3 g6 2. Qf3 Bg7 3. Bc4 e6 4. d4 d5 5. Bb3 Bd7 6. h3 Bc6 7. h4 e5 8. dxe5 d4', '1. e4 e6 2. e5 Qg5 3. d4 c5 4. Bxg5 cxd4 5. Qxd4 Bc5 6. Qxc5 d6 7. Qxd6 Na6 8. Bxa6 Rb8', '1. e4 c5 2. f4 Nc6 3. Nf3 d6 4. Bc4 Bg4 5. O-O Nf6 6. Bxf7+ Kxf7 7. e5 Nd7 8. Ng5+ Kg8', '1. e4 e5 2. f4 d5 3. exd5 exf4 4. Nc3 Qh4+ 5. Ke2 Nf6 6. Nf3 Bg4 7. d3 Be7 8. Bxf4 Bc5', '1. d4 e5 2. dxe5 f6 3. f4 Bc5 4. exf6 Qxf6 5. g3 Nc6 6. e4 Nd4 7. e5 Qb6 8. c3 Nf5', '1. e4 e6 2. e5 d5 3. Nf3 f6 4. d4 fxe5 5. Nxe5 a6 6. Qh5+ Ke7 7. Qf7+ Kd6 8. Bd2 a5', '1. g3 b6 2. Bg2 Nc6 3. c3 Bb7 4. b4 d5 5. b5 Na5 6. a4 e5 7. e4 d4 8. cxd4 Qxd4', '1. e4 e5 2. Bc4 c5 3. d3 Nc6 4. Qf3 f6 5. Bg5 Be7 6. Ne2 h6 7. Be3 g5 8. Qh5+ Kf8', '1. e4 e6 2. d4 d5 3. e5 f6 4. f4 c5 5. exf6 Nxf6 6. dxc5 Bxc5 7. Be3 Qb6 8. Bxc5 Qxc5', '1. e4 e5 2. Nf3 Nc6 3. Bb5 Bc5 4. d3 d6 5. h3 Bd7 6. Nc3 Qf6 7. Nd5 Qg6 8. Nxc7+ Kd8', '1. e4 e5 2. Nf3 Qf6 3. Bc4 Qxf3 4. Qxf3 Nf6 5. Nc3 Nc6 6. Nd5 Nd4 7. Nxf6+ gxf6 8. Qxf6 Rg8', '1. e4 e5 2. Qf3 Nf6 3. d3 Nc6 4. c3 d6 5. h3 Be7 6. Be2 O-O 7. Qg3 Be6 8. Bh6 Re8', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Ng5 d5 5. exd5 Nxd5 6. d3 f6 7. Qh5+ g6 8. Qf3 fxg5', '1. e4 e5 2. d4 exd4 3. Nf3 Nc6 4. Bc4 Bc5 5. O-O d6 6. a3 Bg4 7. b4 Bxf3 8. Qxf3 Bb6', '1. e4 e5 2. Bc4 f6 3. Qf3 d6 4. d3 c5 5. Bg5 h6 6. h4 hxg5 7. hxg5 Rxh1 8. gxf6 Nxf6', '1. e3 b6 2. Qf3 Bb7 3. Qxb7 Nc6 4. Qa6 Nb4 5. Qc4 a5 6. a3 d5 7. Qc3 Nc6 8. Bb5 Nf6', '1. d4 d5 2. Nc3 Nc6 3. Bf4 Nf6 4. Nb5 Nxd4 5. Qxd4 Qd7 6. Nxc7+ Qxc7 7. Bxc7 e6 8. f3 g5', '1. e4 e5 2. f4 exf4 3. Nf3 g5 4. Bc4 g4 5. Bxf7+ Ke7 6. Bb3 gxf3 7. Qxf3 Nf6 8. Qxf4 Bg7', '1. d4 c6 2. e4 d5 3. e5 Nd7 4. f4 f6 5. e6 Nb6 6. f5 g6 7. g4 gxf5 8. gxf5 Nh6', '1. e4 e5 2. Nf3 Bd6 3. Bc4 Qf6 4. O-O h6 5. c3 g5 6. d4 Nc6 7. dxe5 Nxe5 8. Nxe5 Qxe5', '1. d4 d5 2. Nc3 c6 3. e4 Nf6 4. e5 Nfd7 5. f4 h6 6. f5 f6 7. e6 Nb6 8. Qh5+ g6', '1. e4 g6 2. Bc4 Bg7 3. Qf3 e6 4. c3 Nc6 5. d4 Na5 6. Na3 Nxc4 7. Nxc4 b5 8. Ne5 a6', '1. e4 e5 2. Nf3 Bc5 3. Bc4 Qf6 4. d3 Nc6 5. Bg5 Qd6 6. Bc1 Nd4 7. Ng5 Qf6 8. Nxf7 Nb3', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nd4 4. Bxf7+ Kxf7 5. Nxe5+ Ke8 6. Qh5+ Ke7 7. Qf7+ Kd6 8. Nc4+ Kc6', '1. d4 d5 2. a3 c6 3. h3 Nd7 4. e3 e5 5. c3 Bd6 6. b4 Ngf6 7. Bb2 O-O 8. Ne2 Ne4', '1. e4 e6 2. Nf3 b6 3. d4 Bb7 4. Nc3 Ne7 5. Bd3 Ng6 6. O-O Nh4 7. Nxh4 Qxh4 8. g3 Qh3', '1. e4 e5 2. Nf3 Nf6 3. Nxe5 Nxe4 4. Qh5 g6 5. Nxg6 fxg6 6. Qe5+ Qe7 7. Qxh8 Ng3+ 8. Kd1 Nxh1', '1. d4 d5 2. Bf4 e6 3. Nc3 c5 4. dxc5 Bxc5 5. Nf3 Qb6 6. b3 Bxf2+ 7. Kd2 Nf6 8. e3 Nh5', '1. e4 e5 2. Nf3 Nc6 3. Nc3 Bc5 4. Bc4 Nf6 5. d3 Nd4 6. O-O Nxf3+ 7. Qxf3 b6 8. Nd5 Nxd5', '1. d4 e6 2. e4 Bb4+ 3. c3 Ba5 4. b4 Bb6 5. Nf3 Nc6 6. Ng5 Nf6 7. e5 Nd5 8. Qh5 O-O', '1. e4 e5 2. Nf3 Nc6 3. d4 f6 4. dxe5 Nxe5 5. Nxe5 fxe5 6. Qh5+ Ke7 7. Qxe5+ Kf7 8. Qd5+ Kg6', '1. d4 b6 2. c4 Ba6 3. e3 b5 4. cxb5 Bb7 5. Nf3 e6 6. Nc3 Be4 7. Nxe4 c6 8. Ne5 cxb5', '1. e4 Nc6 2. Nf3 e5 3. Bc4 g6 4. Ng5 Nh6 5. d4 exd4 6. Qf3 a6 7. Nxf7 Ne5 8. Nxe5 b5', '1. e4 d6 2. Bc4 e5 3. Nf3 d5 4. Bxd5 Bc5 5. Nxe5 Bd4 6. Bxf7+ Kf8 7. Bb3 Bxe5 8. Qf3+ Ke8', '1. e3 e6 2. Qf3 c6 3. Nh3 a5 4. a3 a4 5. d3 Ra5 6. Bd2 Rb5 7. d4 Rxb2 8. e4 Rxc2', '1. e4 e5 2. Qh5 Nc6 3. Nf3 g6 4. Qh4 Be7 5. Qg3 Nh6 6. Nxe5 Bh4 7. Qc3 Qf6 8. Nxc6 Qxf2+', '1. e4 e5 2. Bc4 Qh4 3. Nf3 Qxe4+ 4. Be2 Qg6 5. Nxe5 Qxg2 6. Bf3 Qg5 7. d4 d6 8. Bxg5 dxe5', '1. e4 Nc6 2. d4 e5 3. d5 Nce7 4. f4 Ng6 5. fxe5 Qh4+ 6. Ke2 Qxe4+ 7. Kf2 Bc5+ 8. Kg3 Qh4+', '1. d4 b6 2. e3 Bb7 3. Nf3 g6 4. Bc4 Bg7 5. Ne5 Bxe5 6. dxe5 Bxg2 7. Rg1 Bb7 8. Nc3 Nc6', '1. e4 d5 2. exd5 Qxd5 3. Nc3 Qe6+ 4. Qe2 Qg6 5. Qe4 Bf5 6. Qxb7 Qe6+ 7. Be2 Bg4 8. f3 Qc6', '1. e4 e5 2. Bc4 Nf6 3. a3 c6 4. Nf3 Nxe4 5. Nxe5 d5 6. Qf3 Qe7 7. Qh3 Bxh3 8. gxh3 Qxe5', '1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Qxd4 Nc6 5. Qc3 Nf6 6. Nbd2 g6 7. b3 Bg7 8. Bb2 O-O', '1. d4 e5 2. dxe5 Na6 3. Nf3 Nh6 4. e4 Bb4+ 5. c3 Ba5 6. Bc4 Nc5 7. Qd5 Bb6 8. O-O Ng4', '1. Nf3 d5 2. d4 c6 3. Bf4 Bg4 4. Ne5 Nf6 5. h3 Bf5 6. e3 Nbd7 7. Nf3 Ne4 8. Nh4 f6', '1. g3 e5 2. Bg2 Nf6 3. Nh3 e4 4. O-O d5 5. e3 Be6 6. d4 Qd7 7. b3 Bxh3 8. Bxh3 Qxh3', '1. e4 g6 2. d4 Bg7 3. Nf3 b6 4. Nc3 Bb7 5. Bc4 h6 6. Ne5 e6 7. Qf3 Nf6 8. d5 exd5', '1. e4 e5 2. Nf3 Nc6 3. Nc3 Nf6 4. Bb5 d6 5. Bxc6+ bxc6 6. d4 exd4 7. Nxd4 d5 8. Nxc6 dxe4', '1. e4 e5 2. Bc4 Nf6 3. Nc3 Bc5 4. Nf3 Ng4 5. O-O Nc6 6. h3 h5 7. hxg4 hxg4 8. Nh2 Qh4', '1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. Ng5 d5 5. exd5 h6 6. Nxf7 Kxf7 7. dxc6+ Nd5 8. Qf3+ Ke8', '1. e4 c5 2. Bc4 e6 3. d3 a5 4. a3 d6 5. Nc3 Nc6 6. Qf3 Nf6 7. Ba2 Be7 8. g4 e5', '1. e4 e5 2. Qh5 Nc6 3. Bb5 g6 4. Qh3 Nd4 5. Qg3 Nxc2+ 6. Kd1 Nxa1 7. Qxe5+ Be7 8. Qxh8 Kf8', '1. c4 d5 2. e3 d4 3. Nf3 dxe3 4. fxe3 Bf5 5. Qb3 b6 6. Qb5+ Bd7 7. Qd5 Nc6 8. Ng5 e6', '1. e4 d5 2. exd5 Qxd5 3. Nc3 Qd8 4. Nf3 f6 5. Bc4 Nh6 6. d4 f5 7. Bxh6 gxh6 8. Ne5 Nc6', '1. d4 d5 2. Nf3 Nf6 3. Nc3 Nc6 4. Bg5 h6 5. Bxf6 gxf6 6. e4 dxe4 7. Nxe4 e5 8. d5 Ne7', '1. e4 e5 2. Ne2 Nf6 3. b3 Bc5 4. Bb2 Nc6 5. a3 d6 6. b4 Bb6 7. c4 a6 8. a4 Nxe4', '1. e4 e5 2. Nf3 Nc6 3. Bc4 h6 4. Nc3 a6 5. d3 Bc5 6. Na4 Ba7 7. Bd5 Nf6 8. Bxc6 dxc6', '1. d4 e6 2. e4 Ne7 3. Nh3 Ng6 4. Qf3 Be7 5. Nc3 O-O 6. e5 d6 7. Bd3 dxe5 8. dxe5 Nxe5', '1. e3 d6 2. Qg4 Qd7 3. Nf3 Qxg4 4. Bd3 Qxf3 5. Nc3 Qxe3+ 6. Kf1 Qxd3+ 7. Kg1 Qxc3 8. a3 Qxc2', '1. e4 c5 2. Nf3 e6 3. d4 Qa5+ 4. Bd2 Qb6 5. dxc5 Bxc5 6. Qe2 Qxb2 7. Bc3 Qc1+ 8. Qd1 Bxf2+', '1. e4 e6 2. d4 b6 3. e5 Bb7 4. Bb5 Bxg2 5. f3 Bxh1 6. d5 Bb4+ 7. c3 Qh4+ 8. Kf1 Bc5', '1. e4 e5 2. Nf3 Bc5 3. Nxe5 b5 4. Qf3 Nh6 5. d4 f6 6. Bxh6 gxh6 7. Qh5+ Ke7 8. dxc5 Rg8', '1. e4 e5 2. Nf3 Nc6 3. Bc4 d6 4. c3 Na5 5. Qa4+ Nc6 6. Bd5 Bd7 7. Qb3 Rb8 8. Bxf7+ Ke7', '1. e4 e6 2. Bc4 d5 3. exd5 exd5 4. Bb3 Nf6 5. d4 c6 6. Nc3 c5 7. dxc5 Nc6 8. Nxd5 Bxc5', '1. e4 e5 2. Nf3 Nc6 3. Nc3 Nf6 4. Bb5 Nd4 5. Nxe5 Nxb5 6. Nxb5 Nxe4 7. d3 Qf6 8. Nxc7+ Kd8', '1. e4 e5 2. Nf3 d6 3. d4 Bg4 4. dxe5 Bxf3 5. Qxf3 dxe5 6. Bc4 Nf6 7. Qb3 Nxe4 8. Bxf7+ Ke7', '1. e4 d5 2. Nf3 dxe4 3. Ng5 Nf6 4. Nc3 b6 5. Bc4 e6 6. f3 exf3 7. Qxf3 c6 8. d3 Nd5', '1. d4 d6 2. Nf3 e5 3. c3 f6 4. Nbd2 d5 5. dxe5 fxe5 6. Nxe5 h5 7. e3 Rh6 8. Qf3 Re6', '1. e4 e5 2. Nf3 d5 3. d4 dxe4 4. Nxe5 f5 5. c3 Nc6 6. Bb5 Bd6 7. Nd2 f4 8. Qb3 Ne7', '1. e4 e5 2. Nf3 Nc6 3. Bb5 Nge7 4. d4 a5 5. d5 Na7 6. Nc3 c6 7. dxc6 bxc6 8. Bc4 Qb6', '1. e3 e5 2. Nc3 Nf6 3. Nf3 e4 4. Ng1 Bb4 5. Nb1 Nc6 6. a3 Bd6 7. b4 O-O 8. Bb2 Ng4', '1. e4 e5 2. Nf3 d5 3. exd5 e4 4. Nd4 Qxd5 5. c3 Bc5 6. Ne2 Nf6 7. h3 e3 8. Nf4 exf2+', '1. d3 d5 2. d4 Nc6 3. c3 Bf5 4. b3 Bxb1 5. Rxb1 Qd6 6. e3 O-O-O 7. c4 dxc4 8. bxc4 e5', '1. e4 d5 2. exd5 Qxd5 3. Nf3 e6 4. Be2 Nc6 5. d3 Bb4+ 6. Bd2 a5 7. c3 Bd6 8. O-O b6', '1. d4 d5 2. e4 dxe4 3. f3 exf3 4. Nxf3 Bg4 5. Bc4 h6 6. Ne5 Be6 7. Bxe6 fxe6 8. Qh5+ g6', '1. e4 e5 2. d3 Bc5 3. Nf3 d6 4. Bd2 Bg4 5. h3 Bxf3 6. Qxf3 Na6 7. Nc3 Nb4 8. Qd1 Qf6', '1. c4 d5 2. cxd5 Qxd5 3. Nc3 Qc6 4. e4 Nf6 5. Bb5 Qxb5 6. Nxb5 Kd8 7. Qc2 a6 8. Qxc7+ Ke8']\n",
        "chess_data = []\n",
        "for mate, ongoing in zip(chess_mates, chess_ongoing):\n",
        "    chess_data += [(ongoing, 'False'), (mate, 'True')]\n",
        "chess_train = random.sample(chess_data[:10], 10)\n",
        "chess_test = random.sample(chess_data[10:], len(chess_data) - 10)"
      ],
      "metadata": {
        "id": "xAFKQb5vQdQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for game in chess_train:\n",
        "    print(game)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rXP0AGCSy4Q",
        "outputId": "02bc9359-7e9c-47da-da87-168f2a311f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('1. e4 e5 2. Nf3 d6 3. Bc4 Nf6 4. Ng5 d5 5. exd5 Nxd5 6. Nxf7 Kxf7 7. Qf3+ Ke8 8. Bxd5 c6', 'False')\n",
            "('1. d4 c5 2. Nf3 cxd4 3. Nxd4 g6 4. Nc3 Bg7 5. e4 Bxd4 6. Qxd4 Nc6 7. Qxh8 Kf8 8. Bh6+ Ke8', 'False')\n",
            "('1. f4 e5 2. fxe5 f6 3. e4 fxe5 4. d3 Qf6 5. Nf3 Bc5 6. Nbd2 g5 7. Be2 g4 8. Ng5 Qf2', 'True')\n",
            "('1. e4 e5 2. Bc4 Nf6 3. d3 d5 4. exd5 Bc5 5. h3 e4 6. Bg5 h6 7. Bxf6 Qxf6 8. dxe4 Qxf2', 'True')\n",
            "('1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Bxc6 dxc6 5. Nxe5 Qg5 6. O-O Qxe5 7. Nc3 Bd6 8. d4 Qxh2', 'True')\n",
            "('1. e4 e5 2. Nf3 Nc6 3. Bb5 Nf6 4. Nc3 d6 5. O-O Ng4 6. h3 h5 7. hxg4 hxg4 8. Nh2 Qh4', 'False')\n",
            "('1. d3 e5 2. Kd2 Bc5 3. Kc3 d5 4. Kb3 d4 5. Kc4 b6 6. e3 Be6+ 7. Kb5 c6+ 8. Ka4 b5', 'True')\n",
            "('1. b3 e5 2. Bb2 e4 3. d3 Nf6 4. Nh3 d5 5. dxe4 Nxe4 6. Nf4 Qh4 7. g3 Bc5 8. f3 Bf2', 'True')\n",
            "('1. d4 d5 2. Nc3 e6 3. a3 Nf6 4. Bg5 Be7 5. e3 O-O 6. h4 Ne4 7. Qd3 Nxg5 8. hxg5 Bxg5', 'False')\n",
            "('1. e4 e5 2. Nf3 d6 3. Bc4 h6 4. O-O f5 5. d4 fxe4 6. Nxe5 dxe5 7. Qh5+ Ke7 8. Qxe5+ Kd7', 'False')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bible Translation\n",
        "Compare a 400-yr-old translation foundational to the English language, to a modern paraphrase"
      ],
      "metadata": {
        "id": "fGbfbAkzaOlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BG_BASE_URL = \"https://www.biblegateway.com/passage/\"\n",
        "\n",
        "VERSES = [\n",
        "    \"Genesis 1:1\",\n",
        "    \"Genesis 1:31\",\n",
        "    \"Exodus 20:3\",\n",
        "    \"Psalm 23:1\",\n",
        "    \"Psalm 103:2\",\n",
        "    \"Psalm 139:1\",\n",
        "    \"Proverbs 3:5\",\n",
        "    \"Isaiah 1:16\",\n",
        "    \"Isaiah 53:5\",\n",
        "    \"John 1:1\",\n",
        "    \"John 3:16\",\n",
        "    \"John 14:6\",\n",
        "    \"Romans 3:23\",\n",
        "    \"Romans 5:8\",\n",
        "    \"Romans 6:23\",\n",
        "    \"Romans 8:28\",\n",
        "    \"1 Corinthians 13:4\",\n",
        "    \"1 Corinthians 13:5\",\n",
        "    \"1 Corinthians 13:6\",\n",
        "    \"1 Corinthians 13:7\",\n",
        "    \"2 Corinthians 5:17\",\n",
        "    \"Galatians 2:20\",\n",
        "    \"Galatians 5:22\",\n",
        "    \"Galatians 5:23\",\n",
        "    \"Ephesians 2:8\",\n",
        "    \"Ephesians 2:9\",\n",
        "    \"Philippians 4:6\",\n",
        "    \"Philippians 4:7\",\n",
        "    \"Philippians 4:13\",\n",
        "    \"Colossians 3:23\",\n",
        "    \"Hebrews 4:12\",\n",
        "    \"Hebrews 11:1\",\n",
        "    \"1 Peter 5:7\",\n",
        "    \"1 John 1:9\",\n",
        "    \"1 John 4:7\",\n",
        "    \"1 John 4:8\",\n",
        "    \"1 John 4:9\",\n",
        "    \"1 John 4:10\",\n",
        "    \"1 John 4:11\",\n",
        "    \"Revelation 3:20\",\n",
        "    \"Revelation 21:4\",\n",
        "    \"Matthew 5:3\",\n",
        "    \"Matthew 5:4\",\n",
        "    \"Matthew 5:5\",\n",
        "    \"Matthew 5:6\",\n",
        "    \"Matthew 5:7\",\n",
        "    \"Matthew 5:8\",\n",
        "    \"Matthew 5:9\",\n",
        "    \"Matthew 28:19\",\n",
        "    \"Matthew 28:20\",\n",
        "    \"Luke 2:10\",\n",
        "    \"Luke 2:11\",\n",
        "    \"Acts 1:8\",\n",
        "    \"Acts 2:38\",\n",
        "    \"James 1:5\"\n",
        "]\n",
        "\n",
        "TRANSLATION_A = \"KJV\"\n",
        "TRANSLATION_B = \"NLT\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"GrantBibleScraper/1.0\"\n",
        "}\n",
        "\n",
        "def fetch_verse_text(reference: str, version: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch a single verse's text from BibleGateway.\n",
        "    Returns plain-ish text (joined paragraphs).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"search\": reference,\n",
        "        \"version\": version\n",
        "    }\n",
        "    resp = requests.get(BG_BASE_URL, params=params, headers=HEADERS, timeout=15)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "    # BibleGateway often wraps the passage in something like:\n",
        "    # <div class=\"passage-text\"> ... </div>\n",
        "    passage_div = soup.find(\"div\", class_=\"passage-text\")\n",
        "    if not passage_div:\n",
        "        # fallback: return whole page text\n",
        "        return soup.get_text(\" \", strip=True)\n",
        "\n",
        "    # Remove footnotes, crossrefs, etc., to clean it up\n",
        "    for fn in passage_div.select(\".footnote, .crossreference, sup, .text-footnotes, .footnotes\"):\n",
        "        fn.decompose()\n",
        "\n",
        "    # Sometimes verses are inside <p class=\"...\"> and <span class=\"text\"> etc.\n",
        "    # We'll just grab visible text:\n",
        "    text_parts = []\n",
        "    for elem in passage_div.find_all([\"p\", \"span\", \"div\"], recursive=True):\n",
        "        t = elem.get_text(\" \", strip=True)\n",
        "        if t:\n",
        "            text_parts.append(t)\n",
        "\n",
        "    # Join and dedupe a bit\n",
        "    full_text = \" \".join(text_parts)\n",
        "    # sometimes BG repeats the reference in the text; you can strip if you want\n",
        "    problem = \" Read full chapter\"\n",
        "    if problem in full_text:\n",
        "        full_text = full_text[:full_text.index(problem)]\n",
        "#    while full_text[0].isdigit():  # This artificially differentiates the texts more than it helps\n",
        "#        full_text = full_text[1:]\n",
        "    return \" \".join(full_text.split())\n",
        "\n",
        "def scrape_verses(references, translations):\n",
        "    rows = []\n",
        "    for ref in references:\n",
        "        for tr in translations:\n",
        "            try:\n",
        "                txt = fetch_verse_text(ref, tr)\n",
        "            except Exception as e:\n",
        "                txt = f\"[ERROR: {e}]\"\n",
        "            rows.append({\n",
        "                \"reference\": ref,\n",
        "                \"translation\": tr,\n",
        "                \"text\": txt\n",
        "            })\n",
        "\n",
        "            # be polite: sleep a little\n",
        "            time.sleep(1 + random.random() / 2)  # ~1–1.5 seconds\n",
        "\n",
        "    return rows\n",
        "\n",
        "def collate_data(rows):\n",
        "    for r in rows:\n",
        "        BT_data.append((r[\"text\"], str(r[\"translation\"] == TRANSLATION_A)))\n",
        "\n",
        "BT_data = []\n",
        "rows = scrape_verses(VERSES, [TRANSLATION_A, TRANSLATION_B])\n",
        "collate_data(rows)\n",
        "print(\"Done. Wrote\", len(rows), \"rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyrI0gPQi1P7",
        "outputId": "150e7866-a238-430c-fef7-e03b29468030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Wrote 110 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BT_train = []\n",
        "for i in random.sample(list(range(5)), 5):\n",
        "    output = BT_data[2 * i:2 * i + 2].copy()\n",
        "    if random.getrandbits(1):\n",
        "        output = output[::-1]\n",
        "    BT_train += output\n",
        "BT_test = BT_data[10:]\n",
        "random.shuffle(BT_test)\n",
        "for verse in BT_train:\n",
        "    print(verse[1], ':', verse[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLp-t2LNmvK3",
        "outputId": "4c780163-7385-44c2-8efc-4a4bca4eddf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : 23 The Lord is my shepherd; I shall not want.\n",
            "False : Psalm 23 A psalm of David. The Lord is my shepherd; I have all that I need.\n",
            "False : “You must not have any other god but me.\n",
            "True : Thou shalt have no other gods before me.\n",
            "False : Then God looked over all he had made, and he saw that it was very good! And evening passed and morning came, marking the sixth day.\n",
            "True : And God saw every thing that he had made, and, behold, it was very good. And the evening and the morning were the sixth day.\n",
            "False : Let all that I am praise the Lord ; may I never forget the good things he does for me.\n",
            "True : Bless the Lord , O my soul, and forget not all his benefits:\n",
            "False : The Account of Creation 1 In the beginning God created the heavens and the earth.\n",
            "True : 1 In the beginning God created the heaven and the earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testament comparison\n",
        "same translation, just comparing a much older text to a (relatively) newer one with a different (though connected) theology"
      ],
      "metadata": {
        "id": "WuSNX8Q8uRRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "old_testament_verses = [\n",
        "    \"Genesis 1:27\",\n",
        "    \"Genesis 2:7\",\n",
        "    \"Genesis 12:3\",\n",
        "    \"Genesis 15:6\",\n",
        "    \"Genesis 22:18\",\n",
        "    \"Exodus 3:14\",\n",
        "    \"Exodus 14:14\",\n",
        "    \"Exodus 20:12\",\n",
        "    \"Exodus 33:14\",\n",
        "    \"Leviticus 19:18\",\n",
        "    \"Numbers 6:24\",\n",
        "    \"Numbers 6:25\",\n",
        "    \"Numbers 6:26\",\n",
        "    \"Deuteronomy 6:5\",\n",
        "    \"Deuteronomy 8:3\",\n",
        "    \"Deuteronomy 30:19\",\n",
        "    \"Joshua 1:9\",\n",
        "    \"1 Samuel 16:7\",\n",
        "    \"2 Samuel 7:16\",\n",
        "    \"1 Kings 8:61\",\n",
        "    \"2 Kings 6:17\",\n",
        "    \"1 Chronicles 16:11\",\n",
        "    \"2 Chronicles 7:14\",\n",
        "    \"Nehemiah 8:10\",\n",
        "    \"Job 1:21\",\n",
        "    \"Job 19:25\",\n",
        "    \"Psalm 19:14\",\n",
        "    \"Psalm 23:4\",\n",
        "    \"Psalm 27:1\",\n",
        "    \"Psalm 34:8\",\n",
        "    \"Psalm 37:4\",\n",
        "    \"Psalm 46:10\",\n",
        "    \"Psalm 51:10\",\n",
        "    \"Psalm 91:11\",\n",
        "    \"Psalm 119:105\",\n",
        "    \"Proverbs 3:5\",\n",
        "    \"Proverbs 3:6\",\n",
        "    \"Proverbs 9:10\",\n",
        "    \"Proverbs 16:9\",\n",
        "    \"Proverbs 27:17\",\n",
        "    \"Ecclesiastes 3:11\",\n",
        "    \"Isaiah 7:14\",\n",
        "    \"Isaiah 9:6\",\n",
        "    \"Isaiah 26:3\",\n",
        "    \"Isaiah 40:31\",\n",
        "    \"Isaiah 41:10\",\n",
        "    \"Isaiah 53:5\",\n",
        "    \"Jeremiah 17:7\",\n",
        "    \"Jeremiah 29:11\",\n",
        "    \"Lamentations 3:22\",\n",
        "    \"Lamentations 3:23\",\n",
        "    \"Ezekiel 36:26\",\n",
        "    \"Micah 6:8\",\n",
        "    \"Habakkuk 3:19\",\n",
        "    \"Zechariah 4:6\"\n",
        "]\n",
        "new_testament_verses = [\n",
        "    \"Matthew 5:9\",\n",
        "    \"Matthew 5:14\",\n",
        "    \"Matthew 5:16\",\n",
        "    \"Matthew 6:21\",\n",
        "    \"Matthew 6:33\",\n",
        "    \"Matthew 7:7\",\n",
        "    \"Matthew 7:12\",\n",
        "    \"Matthew 11:28\",\n",
        "    \"Matthew 22:37\",\n",
        "    \"Matthew 22:39\",\n",
        "    \"Matthew 28:19\",\n",
        "    \"Matthew 28:20\",\n",
        "    \"Mark 8:36\",\n",
        "    \"Mark 9:24\",\n",
        "    \"Mark 10:27\",\n",
        "    \"Mark 12:30\",\n",
        "    \"Luke 1:37\",\n",
        "    \"Luke 6:31\",\n",
        "    \"Luke 12:34\",\n",
        "    \"Luke 23:34\",\n",
        "    \"John 3:16\",\n",
        "    \"John 6:35\",\n",
        "    \"John 8:12\",\n",
        "    \"John 11:25\",\n",
        "    \"John 13:34\",\n",
        "    \"John 14:6\",\n",
        "    \"John 14:27\",\n",
        "    \"John 15:5\",\n",
        "    \"John 15:13\",\n",
        "    \"Acts 1:8\",\n",
        "    \"Acts 2:38\",\n",
        "    \"Acts 4:12\",\n",
        "    \"Romans 3:23\",\n",
        "    \"Romans 5:8\",\n",
        "    \"Romans 6:23\",\n",
        "    \"Romans 8:1\",\n",
        "    \"Romans 8:28\",\n",
        "    \"Romans 12:2\",\n",
        "    \"1 Corinthians 10:13\",\n",
        "    \"1 Corinthians 13:4\",\n",
        "    \"1 Corinthians 13:13\",\n",
        "    \"2 Corinthians 4:18\",\n",
        "    \"2 Corinthians 5:17\",\n",
        "    \"Galatians 2:20\",\n",
        "    \"Galatians 5:22\",\n",
        "    \"Galatians 5:23\",\n",
        "    \"Ephesians 2:8\",\n",
        "    \"Ephesians 2:9\",\n",
        "    \"Philippians 4:6\",\n",
        "    \"Philippians 4:7\",\n",
        "    \"Philippians 4:13\",\n",
        "    \"Colossians 3:23\",\n",
        "    \"1 Thessalonians 5:16\",\n",
        "    \"1 Thessalonians 5:17\",\n",
        "    \"2 Timothy 1:7\"\n",
        "]\n",
        "\n",
        "Testament_data = []\n",
        "rows = scrape_verses(old_testament_verses, [\"KJV\"])\n",
        "for r in rows:\n",
        "    Testament_data.append((r[\"text\"], 'False'))\n",
        "rows = scrape_verses(new_testament_verses, [\"KJV\"])\n",
        "for r in rows:\n",
        "    Testament_data.append((r[\"text\"], 'True'))"
      ],
      "metadata": {
        "id": "ZhAULM1-unJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Testament_train = Testament_data[:5] + Testament_data[-5:]\n",
        "random.shuffle(Testament_train)\n",
        "Testament_test = Testament_data[5:-5]\n",
        "random.shuffle(Testament_test)\n",
        "\n",
        "for verse in Testament_train:\n",
        "    print(verse[1], ':', verse[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76hAt1m6wX_u",
        "outputId": "66c32824-f930-43e8-9507-193fb31ef8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : And whatsoever ye do, do it heartily, as to the Lord, and not unto men;\n",
            "True : For God hath not given us the spirit of fear; but of power, and of love, and of a sound mind.\n",
            "False : And the Lord God formed man of the dust of the ground, and breathed into his nostrils the breath of life; and man became a living soul.\n",
            "False : And I will bless them that bless thee, and curse him that curseth thee: and in thee shall all families of the earth be blessed.\n",
            "False : And he believed in the Lord ; and he counted it to him for righteousness.\n",
            "False : And in thy seed shall all the nations of the earth be blessed; because thou hast obeyed my voice.\n",
            "True : Rejoice evermore.\n",
            "True : Pray without ceasing.\n",
            "False : So God created man in his own image, in the image of God created he him; male and female created he them.\n",
            "True : I can do all things through Christ which strengtheneth me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Book ID\n",
        "Since Testament didn't quite hit 0.9, let's compare one of the most iconic sections of each"
      ],
      "metadata": {
        "id": "su3BLCJ3zjMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "commandment_verses = [f\"Exodus 20:{n}\" for n in range(1, 27)] + [f\"Exodus 21:{n}\" for n in range(1, 30)]\n",
        "SotM_verses = [f\"Matthew 5:{n}\" for n in range(3, 49)] + [f\"Matthew 6:{n}\" for n in range(1, 10)]\n",
        "ExMatt_data = []\n",
        "rows = scrape_verses(commandment_verses, [\"KJV\"])\n",
        "for r in rows:\n",
        "    ExMatt_data.append((r[\"text\"], 'False'))\n",
        "rows = scrape_verses(SotM_verses, [\"KJV\"])\n",
        "for r in rows:\n",
        "    ExMatt_data.append((r[\"text\"], 'True'))"
      ],
      "metadata": {
        "id": "kVl4veKoz4JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ExMatt_train = ExMatt_data[:5] + ExMatt_data[-5:]\n",
        "random.shuffle(ExMatt_train)\n",
        "ExMatt_test = ExMatt_data[5:-5]\n",
        "random.shuffle(ExMatt_test)\n",
        "\n",
        "for verse in ExMatt_train:\n",
        "    print(verse[1], ':', verse[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBvHYJWp1xHu",
        "outputId": "8ddeb65c-09ec-4192-ab0d-3032f7eddbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False : 20 And God spake all these words, saying,\n",
            "False : Thou shalt have no other gods before me.\n",
            "True : And when thou prayest, thou shalt not be as the hypocrites are: for they love to pray standing in the synagogues and in the corners of the streets, that they may be seen of men. Verily I say unto you, They have their reward.\n",
            "True : Be not ye therefore like unto them: for your Father knoweth what things ye have need of, before ye ask him.\n",
            "True : After this manner therefore pray ye: Our Father which art in heaven, Hallowed be thy name.\n",
            "True : But thou, when thou prayest, enter into thy closet, and when thou hast shut thy door, pray to thy Father which is in secret; and thy Father which seeth in secret shall reward thee openly.\n",
            "False : Thou shalt not bow down thyself to them, nor serve them: for I the Lord thy God am a jealous God, visiting the iniquity of the fathers upon the children unto the third and fourth generation of them that hate me;\n",
            "False : Thou shalt not make unto thee any graven image, or any likeness of any thing that is in heaven above, or that is in the earth beneath, or that is in the water under the earth.\n",
            "True : But when ye pray, use not vain repetitions, as the heathen do: for they think that they shall be heard for their much speaking.\n",
            "False : I am the Lord thy God, which have brought thee out of the land of Egypt, out of the house of bondage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quadratics\n",
        "Does the quadratic have real root(s), i.e. does the parabola pass through the *x*-axis?"
      ],
      "metadata": {
        "id": "omMubKCl3gID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs = [(random.randint(5, 20), random.randint(5,20)) for _ in range(110)]\n",
        "for i, cs in enumerate(coeffs):\n",
        "    b = int(2 * statistics.geometric_mean(cs))\n",
        "    if i < 55:\n",
        "        coeffs[i] = (cs[0], random.randint(1, b) ,cs[1])\n",
        "    else:\n",
        "        coeffs[i] = (cs[0], random.randint(b + 1, 50), cs[1])\n",
        "Quad_data = [(f\"{a} x^2 + {b} x + {c}\", str(b ** 2 >= 4 * a * c)) for a, b, c in coeffs]\n",
        "\n",
        "Quad_train = Quad_data[:5] + Quad_data[-5:]\n",
        "random.shuffle(Quad_train)\n",
        "Quad_test = Quad_data[5:-5]\n",
        "random.shuffle(Quad_test)\n",
        "\n",
        "for quad in Quad_train:\n",
        "    print(quad[1], ':', quad[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxlS1I633x1Z",
        "outputId": "5ab77e13-449f-4e98-bf08-a63663726fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : 14 x^2 + 43 x + 10\n",
            "False : 12 x^2 + 19 x + 9\n",
            "False : 6 x^2 + 3 x + 15\n",
            "True : 9 x^2 + 34 x + 16\n",
            "False : 10 x^2 + 12 x + 10\n",
            "True : 11 x^2 + 34 x + 7\n",
            "True : 16 x^2 + 34 x + 13\n",
            "False : 7 x^2 + 14 x + 18\n",
            "False : 8 x^2 + 6 x + 13\n",
            "True : 8 x^2 + 29 x + 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Is/ought"
      ],
      "metadata": {
        "id": "CFSZMGZOEMhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of 55 random descriptive statements.\", model=my_model_list[-1], max_tokens=1200)\n",
        "description = response.completion\n",
        "print(description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fXvmVngOEQy_",
        "outputId": "599c4576-94a2-468a-b0de-4599b55a1609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 random descriptive statements:\n",
            "\n",
            "1. The old lighthouse stands weathered against relentless ocean winds.\n",
            "2. Coffee steam curls lazily through morning sunlight.\n",
            "3. Her laughter sounds like wind chimes in a summer breeze.\n",
            "4. The abandoned factory looms silent and rust-covered.\n",
            "5. Fresh snow muffles every sound in the forest.\n",
            "6. His handwriting slants sharply to the left.\n",
            "7. The cat's eyes glow amber in the darkness.\n",
            "8. Dust particles dance in the afternoon light beam.\n",
            "9. The leather jacket smells of motorcycle exhaust and rain.\n",
            "10. Cherry blossoms drift like pink snow across the path.\n",
            "11. The clock tower chimes echo through empty streets.\n",
            "12. Her fingernails are painted midnight blue with silver specks.\n",
            "13. The soup tastes of rosemary and childhood memories.\n",
            "14. Fog rolls thick between the mountain valleys.\n",
            "15. The violin case is covered in faded travel stickers.\n",
            "16. His beard grows in uneven copper patches.\n",
            "17. The library smells of old paper and vanilla.\n",
            "18. Rain drums steadily on the tin roof.\n",
            "19. The mirror reflects a distorted version of reality.\n",
            "20. Moss covers the north side of every tree trunk.\n",
            "21. The dog's tail wags in perfect circles.\n",
            "22. Candlelight flickers against stone walls.\n",
            "23. The sweater feels rough like sheep's wool.\n",
            "24. Ice crystals form delicate patterns on the window.\n",
            "25. The market buzzes with overlapping conversations.\n",
            "26. Her voice cracks slightly when she's nervous.\n",
            "27. The floorboards creak in a specific rhythm.\n",
            "28. Sunflowers turn their faces east at dawn.\n",
            "29. The pencil marks fade gradually across the page.\n",
            "30. Salt air corrodes the metal fence posts.\n",
            "31. The tea kettle whistles in B-flat.\n",
            "32. Shadows stretch long across the empty parking lot.\n",
            "33. The fabric pills where friction occurs most.\n",
            "34. Honey moves slowly down the jar's side.\n",
            "35. The room temperature drops near the corner window.\n",
            "36. Birds gather on power lines before storms.\n",
            "37. The paint peels in hexagonal patterns.\n",
            "38. Her shoes click precisely on marble floors.\n",
            "39. The bread crust shatters into golden flakes.\n",
            "40. Moonlight turns the lake surface silver.\n",
            "41. The engine makes a subtle ticking sound when cooling.\n",
            "42. Dust settles thickest in forgotten corners.\n",
            "43. The photograph yellows at its edges.\n",
            "44. Wind makes the wheat field look like an ocean.\n",
            "45. The doorknob always sticks slightly when turning left.\n",
            "46. Frost makes the grass crunch underfoot.\n",
            "47. The ceiling fan wobbles on its highest setting.\n",
            "48. Her perfume lingers in the elevator.\n",
            "49. The concrete shows hairline cracks spreading outward.\n",
            "50. Morning dew beads perfectly on spider webs.\n",
            "51. The radio static increases near the bridge.\n",
            "52. Rust blooms orange across the ship's hull.\n",
            "53. The curtains fade unevenly where sun hits directly.\n",
            "54. His footsteps echo in the underground tunnel.\n",
            "55. The candle wax pools unevenly to one side.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_statements = description.split('. ')[1:]\n",
        "for i, statement in enumerate(descriptive_statements):\n",
        "    descriptive_statements[i] = statement.strip('1234567890').strip()\n",
        "for statement in descriptive_statements:\n",
        "    print(statement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNd84K4CFlik",
        "outputId": "8c733984-17ba-4ac0-d497-2cf5fe322e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The old lighthouse stands weathered against relentless ocean winds.\n",
            "Coffee steam curls lazily through morning sunlight.\n",
            "Her laughter sounds like wind chimes in a summer breeze.\n",
            "The abandoned factory looms silent and rust-covered.\n",
            "Fresh snow muffles every sound in the forest.\n",
            "His handwriting slants sharply to the left.\n",
            "The cat's eyes glow amber in the darkness.\n",
            "Dust particles dance in the afternoon light beam.\n",
            "The leather jacket smells of motorcycle exhaust and rain.\n",
            "Cherry blossoms drift like pink snow across the path.\n",
            "The clock tower chimes echo through empty streets.\n",
            "Her fingernails are painted midnight blue with silver specks.\n",
            "The soup tastes of rosemary and childhood memories.\n",
            "Fog rolls thick between the mountain valleys.\n",
            "The violin case is covered in faded travel stickers.\n",
            "His beard grows in uneven copper patches.\n",
            "The library smells of old paper and vanilla.\n",
            "Rain drums steadily on the tin roof.\n",
            "The mirror reflects a distorted version of reality.\n",
            "Moss covers the north side of every tree trunk.\n",
            "The dog's tail wags in perfect circles.\n",
            "Candlelight flickers against stone walls.\n",
            "The sweater feels rough like sheep's wool.\n",
            "Ice crystals form delicate patterns on the window.\n",
            "The market buzzes with overlapping conversations.\n",
            "Her voice cracks slightly when she's nervous.\n",
            "The floorboards creak in a specific rhythm.\n",
            "Sunflowers turn their faces east at dawn.\n",
            "The pencil marks fade gradually across the page.\n",
            "Salt air corrodes the metal fence posts.\n",
            "The tea kettle whistles in B-flat.\n",
            "Shadows stretch long across the empty parking lot.\n",
            "The fabric pills where friction occurs most.\n",
            "Honey moves slowly down the jar's side.\n",
            "The room temperature drops near the corner window.\n",
            "Birds gather on power lines before storms.\n",
            "The paint peels in hexagonal patterns.\n",
            "Her shoes click precisely on marble floors.\n",
            "The bread crust shatters into golden flakes.\n",
            "Moonlight turns the lake surface silver.\n",
            "The engine makes a subtle ticking sound when cooling.\n",
            "Dust settles thickest in forgotten corners.\n",
            "The photograph yellows at its edges.\n",
            "Wind makes the wheat field look like an ocean.\n",
            "The doorknob always sticks slightly when turning left.\n",
            "Frost makes the grass crunch underfoot.\n",
            "The ceiling fan wobbles on its highest setting.\n",
            "Her perfume lingers in the elevator.\n",
            "The concrete shows hairline cracks spreading outward.\n",
            "Morning dew beads perfectly on spider webs.\n",
            "The radio static increases near the bridge.\n",
            "Rust blooms orange across the ship's hull.\n",
            "The curtains fade unevenly where sun hits directly.\n",
            "His footsteps echo in the underground tunnel.\n",
            "The candle wax pools unevenly to one side.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of 55 random normative statements.\", model=my_model_list[-1], max_tokens=1200)\n",
        "prescription = response.completion\n",
        "print(prescription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJr0MYSpG9Z8",
        "outputId": "cb1ed20a-4d84-449d-8711-7718268a4e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 random normative statements:\n",
            "\n",
            "1. People should volunteer in their communities at least once a month.\n",
            "2. Companies ought to provide paid parental leave for all employees.\n",
            "3. Children should learn a second language before age 10.\n",
            "4. Wealthy nations must contribute more to global climate initiatives.\n",
            "5. Everyone should read for pleasure at least 30 minutes daily.\n",
            "6. Governments ought to provide free public transportation.\n",
            "7. People should limit social media use to one hour per day.\n",
            "8. All buildings must be designed with wheelchair accessibility.\n",
            "9. Citizens should vote in every election they're eligible for.\n",
            "10. Restaurants ought to donate leftover food to shelters.\n",
            "11. Everyone should learn basic first aid skills.\n",
            "12. Employers must offer flexible work arrangements.\n",
            "13. People ought to apologize when they're wrong.\n",
            "14. Schools should teach financial literacy as a core subject.\n",
            "15. Adults should get eight hours of sleep nightly.\n",
            "16. Corporations must prioritize environmental sustainability over profits.\n",
            "17. Everyone should practice active listening in conversations.\n",
            "18. Cities ought to maintain more green spaces.\n",
            "19. People should tip service workers generously.\n",
            "20. Universities must make education more affordable.\n",
            "21. Everyone ought to reduce meat consumption.\n",
            "22. Neighbors should look out for each other's safety.\n",
            "23. Technology companies must protect user privacy better.\n",
            "24. People should write thank-you notes for gifts.\n",
            "25. Governments ought to invest more in renewable energy.\n",
            "26. Everyone should learn to cook basic meals.\n",
            "27. Museums must return artifacts to their countries of origin.\n",
            "28. People ought to use reusable bags when shopping.\n",
            "29. Parents should limit children's screen time.\n",
            "30. Workplaces must address mental health seriously.\n",
            "31. Everyone should practice gratitude daily.\n",
            "32. Politicians ought to be more transparent about funding sources.\n",
            "33. People should support local businesses over chains.\n",
            "34. Schools must provide free lunch to all students.\n",
            "35. Adults ought to exercise at least three times weekly.\n",
            "36. Everyone should fact-check before sharing news online.\n",
            "37. Landlords must maintain safe living conditions.\n",
            "38. People should compost organic waste.\n",
            "39. Doctors ought to spend more time with patients.\n",
            "40. Everyone must respect others' religious beliefs.\n",
            "41. Cities should invest more in public libraries.\n",
            "42. People ought to learn from their mistakes.\n",
            "43. Employers should provide professional development opportunities.\n",
            "44. Everyone must take responsibility for their actions.\n",
            "45. Communities should organize neighborhood cleanups.\n",
            "46. People ought to practice empathy toward strangers.\n",
            "47. Governments should regulate artificial intelligence development.\n",
            "48. Everyone should know their neighbors' names.\n",
            "49. Companies must pay living wages to all workers.\n",
            "50. People should disconnect from devices during meals.\n",
            "51. Schools ought to start classes later in the morning.\n",
            "52. Everyone should learn basic home repair skills.\n",
            "53. Media outlets must report news without bias.\n",
            "54. People ought to give compliments more freely.\n",
            "55. Society should value teachers more highly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normative_statements = prescription.split('. ')[1:]\n",
        "for i, statement in enumerate(normative_statements):\n",
        "    normative_statements[i] = statement.strip('1234567890').strip()\n",
        "for statement in normative_statements:\n",
        "    print(statement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euggjc_cHeec",
        "outputId": "0703298f-7f3b-4bf7-bbdb-47ab7b5608ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People should volunteer in their communities at least once a month.\n",
            "Companies ought to provide paid parental leave for all employees.\n",
            "Children should learn a second language before age 10.\n",
            "Wealthy nations must contribute more to global climate initiatives.\n",
            "Everyone should read for pleasure at least 30 minutes daily.\n",
            "Governments ought to provide free public transportation.\n",
            "People should limit social media use to one hour per day.\n",
            "All buildings must be designed with wheelchair accessibility.\n",
            "Citizens should vote in every election they're eligible for.\n",
            "Restaurants ought to donate leftover food to shelters.\n",
            "Everyone should learn basic first aid skills.\n",
            "Employers must offer flexible work arrangements.\n",
            "People ought to apologize when they're wrong.\n",
            "Schools should teach financial literacy as a core subject.\n",
            "Adults should get eight hours of sleep nightly.\n",
            "Corporations must prioritize environmental sustainability over profits.\n",
            "Everyone should practice active listening in conversations.\n",
            "Cities ought to maintain more green spaces.\n",
            "People should tip service workers generously.\n",
            "Universities must make education more affordable.\n",
            "Everyone ought to reduce meat consumption.\n",
            "Neighbors should look out for each other's safety.\n",
            "Technology companies must protect user privacy better.\n",
            "People should write thank-you notes for gifts.\n",
            "Governments ought to invest more in renewable energy.\n",
            "Everyone should learn to cook basic meals.\n",
            "Museums must return artifacts to their countries of origin.\n",
            "People ought to use reusable bags when shopping.\n",
            "Parents should limit children's screen time.\n",
            "Workplaces must address mental health seriously.\n",
            "Everyone should practice gratitude daily.\n",
            "Politicians ought to be more transparent about funding sources.\n",
            "People should support local businesses over chains.\n",
            "Schools must provide free lunch to all students.\n",
            "Adults ought to exercise at least three times weekly.\n",
            "Everyone should fact-check before sharing news online.\n",
            "Landlords must maintain safe living conditions.\n",
            "People should compost organic waste.\n",
            "Doctors ought to spend more time with patients.\n",
            "Everyone must respect others' religious beliefs.\n",
            "Cities should invest more in public libraries.\n",
            "People ought to learn from their mistakes.\n",
            "Employers should provide professional development opportunities.\n",
            "Everyone must take responsibility for their actions.\n",
            "Communities should organize neighborhood cleanups.\n",
            "People ought to practice empathy toward strangers.\n",
            "Governments should regulate artificial intelligence development.\n",
            "Everyone should know their neighbors' names.\n",
            "Companies must pay living wages to all workers.\n",
            "People should disconnect from devices during meals.\n",
            "Schools ought to start classes later in the morning.\n",
            "Everyone should learn basic home repair skills.\n",
            "Media outlets must report news without bias.\n",
            "People ought to give compliments more freely.\n",
            "Society should value teachers more highly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IO_data = [(d, 'False') for d in descriptive_statements] + [(n, 'True') for n in normative_statements]\n",
        "IO_train = IO_data[:5] + IO_data[-5:]\n",
        "random.shuffle(IO_train)\n",
        "IO_test = IO_data[5:-5]\n",
        "random.shuffle(IO_test)\n",
        "\n",
        "for datum in IO_train:\n",
        "    print(datum[1], ':', datum[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um9WkWhkHquS",
        "outputId": "884d89ef-9553-4f33-bd52-cff0e9657b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False : The old lighthouse stands weathered against relentless ocean winds.\n",
            "True : People ought to give compliments more freely.\n",
            "True : Media outlets must report news without bias.\n",
            "False : Fresh snow muffles every sound in the forest.\n",
            "False : Her laughter sounds like wind chimes in a summer breeze.\n",
            "False : The abandoned factory looms silent and rust-covered.\n",
            "True : Society should value teachers more highly.\n",
            "False : Coffee steam curls lazily through morning sunlight.\n",
            "True : Schools ought to start classes later in the morning.\n",
            "True : Everyone should learn basic home repair skills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## He/She"
      ],
      "metadata": {
        "id": "6B-I8A4IIteP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of 55 random statements about Ash, each featuring a masculine pronoun.\", model=my_model_list[-1], max_tokens=1200)\n",
        "history = response.completion\n",
        "print(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekN-_9jWIs0K",
        "outputId": "2e6048b5-1991-4b24-d636-664c8d6c2260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 random statements about Ash featuring masculine pronouns:\n",
            "\n",
            "1. Ash tied his shoes before heading out for a morning run.\n",
            "2. He always preferred coffee over tea in the mornings.\n",
            "3. His collection of vintage records filled three shelves in his apartment.\n",
            "4. Ash forgot his umbrella and got caught in the rain.\n",
            "5. He learned to play chess from his grandfather when he was eight.\n",
            "6. His favorite season was autumn because he loved the changing leaves.\n",
            "7. Ash kept his promises, no matter how difficult they were to fulfill.\n",
            "8. He couldn't resist stopping at the bookstore on his way home.\n",
            "9. His cat always greeted him at the door after work.\n",
            "10. Ash taught himself how to juggle during a boring summer.\n",
            "11. He never missed his weekly call with his best friend.\n",
            "12. His handwriting was surprisingly neat for someone who wrote so quickly.\n",
            "13. Ash fixed his neighbor's bicycle without being asked.\n",
            "14. He had a habit of humming while he cooked dinner.\n",
            "15. His dream was to visit every national park in the country.\n",
            "16. Ash kept a journal where he wrote his thoughts every evening.\n",
            "17. He always double-checked that he locked his front door.\n",
            "18. His favorite movie was one he'd discovered by accident.\n",
            "19. Ash taught his nephew how to ride a bike last summer.\n",
            "20. He preferred walking to driving whenever possible.\n",
            "21. His garden tomatoes won first prize at the county fair.\n",
            "22. Ash organized his bookshelf by color rather than alphabetically.\n",
            "23. He could never remember where he left his reading glasses.\n",
            "24. His homemade pasta sauce was legendary among his friends.\n",
            "25. Ash volunteered at the animal shelter on his weekends.\n",
            "26. He always carried a spare phone charger in his backpack.\n",
            "27. His morning routine included fifteen minutes of meditation.\n",
            "28. Ash learned to speak three languages before his thirtieth birthday.\n",
            "29. He kept a lucky penny in his wallet at all times.\n",
            "30. His photography hobby turned into a successful side business.\n",
            "31. Ash repaired his own car whenever he could manage it.\n",
            "32. He never went to bed angry after an argument.\n",
            "33. His favorite childhood memory was building forts with his siblings.\n",
            "34. Ash practiced his guitar every evening after dinner.\n",
            "35. He always remembered birthdays and sent handwritten cards.\n",
            "36. His apartment walls were covered with maps from his travels.\n",
            "37. Ash rescued a stray dog and it became his best companion.\n",
            "38. He preferred old books with their distinctive musty smell.\n",
            "39. His grandmother's recipe box was his most treasured possession.\n",
            "40. Ash taught himself to code by watching online tutorials.\n",
            "41. He could identify birds by their songs alone.\n",
            "42. His morning jog took him through the park and past the lake.\n",
            "43. Ash kept his workspace meticulously organized.\n",
            "44. He had a talent for remembering people's names after meeting them once.\n",
            "45. His favorite hobby was restoring old furniture he found at yard sales.\n",
            "46. Ash always carried a notebook to jot down his ideas.\n",
            "47. He learned to bake bread during a particularly cold winter.\n",
            "48. His laugh was contagious and filled the entire room.\n",
            "49. Ash donated his hair when it grew long enough.\n",
            "50. He could solve a Rubik's cube in under two minutes.\n",
            "51. His collection of houseplants had grown to over thirty.\n",
            "52. Ash never missed his annual camping trip with his college friends.\n",
            "53. He always offered his seat on public transportation.\n",
            "54. His signature dish was a spicy curry he perfected over years.\n",
            "55. Ash kept his grandfather's watch even though it no longer worked.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of 55 random statements about Ash, each featuring a feminine pronoun.\", model=my_model_list[-1], max_tokens=1200)\n",
        "herstory = response.completion\n",
        "print(herstory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA0sFR3pJb44",
        "outputId": "1b187c6b-b1a7-479c-fe4a-c65c915e7780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 random statements about Ash featuring feminine pronouns:\n",
            "\n",
            "1. Ash loves to paint landscapes in her free time.\n",
            "2. She recently adopted a rescue cat named Whiskers.\n",
            "3. Her favorite season is autumn because of the changing leaves.\n",
            "4. Ash taught herself to play the ukulele last year.\n",
            "5. She makes the best chocolate chip cookies in her neighborhood.\n",
            "6. Her morning routine always includes yoga and green tea.\n",
            "7. Ash keeps a journal where she writes poetry every night.\n",
            "8. She speaks three languages fluently.\n",
            "9. Her grandmother's vintage necklace is her most treasured possession.\n",
            "10. Ash runs a small bookshop downtown that she inherited.\n",
            "11. She has a terrible sense of direction but loves road trips.\n",
            "12. Her laugh is so contagious that everyone around her starts smiling.\n",
            "13. Ash grows tomatoes and herbs in her balcony garden.\n",
            "14. She can never resist buying new houseplants.\n",
            "15. Her favorite movie is a 1940s noir film she discovered randomly.\n",
            "16. Ash volunteers at the animal shelter on weekends.\n",
            "17. She has been collecting vinyl records since she was fifteen.\n",
            "18. Her coffee order is always a double shot cappuccino.\n",
            "19. Ash taught her nephew how to ride a bicycle last summer.\n",
            "20. She dreams of visiting Iceland to see the northern lights.\n",
            "21. Her apartment walls are covered with her own artwork.\n",
            "22. Ash can solve a Rubik's cube in under two minutes.\n",
            "23. She always wears mismatched socks on purpose.\n",
            "24. Her favorite childhood memory is building sandcastles with her dad.\n",
            "25. Ash started a community garden project in her neighborhood.\n",
            "26. She has read every book in her local library's mystery section.\n",
            "27. Her homemade pasta sauce recipe is a closely guarded secret.\n",
            "28. Ash plays chess online every Thursday evening.\n",
            "29. She once won a pie-eating contest at the county fair.\n",
            "30. Her car is named Beatrice and has 200,000 miles on it.\n",
            "31. Ash teaches pottery classes at the community center.\n",
            "32. She always carries a sketchbook in her backpack.\n",
            "33. Her favorite constellation is Cassiopeia.\n",
            "34. Ash learned to knit from YouTube videos during quarantine.\n",
            "35. She has a collection of over 50 different tea varieties.\n",
            "36. Her hiking boots have traveled through seven national parks.\n",
            "37. Ash sends handwritten letters to her friends on their birthdays.\n",
            "38. She can juggle four balls at once.\n",
            "39. Her favorite podcast is about unsolved mysteries.\n",
            "40. Ash built her own computer from scratch.\n",
            "41. She names all her houseplants after famous scientists.\n",
            "42. Her grandmother taught her how to make traditional dumplings.\n",
            "43. Ash has been learning sign language for two years.\n",
            "44. She always keeps emergency chocolate in her desk drawer.\n",
            "45. Her favorite sound is rain on the roof.\n",
            "46. Ash restored an old bicycle she found at a garage sale.\n",
            "47. She writes restaurant reviews for a local blog.\n",
            "48. Her lucky number has always been thirteen.\n",
            "49. Ash can whistle entire symphonies from memory.\n",
            "50. She collects vintage postcards from thrift stores.\n",
            "51. Her neighbors often ask her for plant care advice.\n",
            "52. Ash makes her own candles with essential oils.\n",
            "53. She learned to surf during a trip to California.\n",
            "54. Her favorite breakfast is French toast with maple syrup.\n",
            "55. Ash keeps bees on her rooftop and harvests her own honey.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "his = history.split('. ')[1:]\n",
        "for i, statement in enumerate(his):\n",
        "    his[i] = statement.strip('1234567890').strip()\n",
        "\n",
        "hers = herstory.split('. ')[1:]\n",
        "for i, statement in enumerate(hers):\n",
        "    hers[i] = statement.strip('1234567890').strip()\n",
        "\n",
        "Pronoun_data = [(h, 'False') for h in his] + [(h, 'True') for h in hers]\n",
        "Pronoun_train = Pronoun_data[:5] + Pronoun_data[-5:]\n",
        "random.shuffle(Pronoun_train)\n",
        "Pronoun_test = Pronoun_data[5:-5]\n",
        "random.shuffle(Pronoun_test)\n",
        "\n",
        "for datum in Pronoun_train:\n",
        "    print(datum[1], ':', datum[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMYtZhv_KOU5",
        "outputId": "3366c1bf-fe47-4a60-f08f-677cdcda05ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : Ash keeps bees on her rooftop and harvests her own honey.\n",
            "True : Her favorite breakfast is French toast with maple syrup.\n",
            "True : Her neighbors often ask her for plant care advice.\n",
            "False : He learned to play chess from his grandfather when he was eight.\n",
            "False : He always preferred coffee over tea in the mornings.\n",
            "True : Ash makes her own candles with essential oils.\n",
            "False : Ash forgot his umbrella and got caught in the rain.\n",
            "False : His collection of vintage records filled three shelves in his apartment.\n",
            "False : Ash tied his shoes before heading out for a morning run.\n",
            "True : She learned to surf during a trip to California.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Animal sounds"
      ],
      "metadata": {
        "id": "tQLnibhOLUDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of 55 random animal sounds --- just the sound, no identifier.\", model=my_model_list[-1], max_tokens=1200)\n",
        "moos = response.completion\n",
        "print(moos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SurHsQETLWyh",
        "outputId": "fae7a121-6551-4f66-f6ed-6a63fdef5dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 random animal sounds:\n",
            "\n",
            "1. Moo\n",
            "2. Chirp\n",
            "3. Roar\n",
            "4. Ribbit\n",
            "5. Neigh\n",
            "6. Squeak\n",
            "7. Howl\n",
            "8. Cluck\n",
            "9. Buzz\n",
            "10. Hiss\n",
            "11. Oink\n",
            "12. Tweet\n",
            "13. Growl\n",
            "14. Croak\n",
            "15. Baa\n",
            "16. Screech\n",
            "17. Woof\n",
            "18. Caw\n",
            "19. Meow\n",
            "20. Trumpet\n",
            "21. Gobble\n",
            "22. Chatter\n",
            "23. Bark\n",
            "24. Coo\n",
            "25. Grunt\n",
            "26. Warble\n",
            "27. Bleat\n",
            "28. Click\n",
            "29. Purr\n",
            "30. Honk\n",
            "31. Snarl\n",
            "32. Peep\n",
            "33. Bray\n",
            "34. Squawk\n",
            "35. Mew\n",
            "36. Trill\n",
            "37. Snort\n",
            "38. Hoot\n",
            "39. Yip\n",
            "40. Crow\n",
            "41. Whimper\n",
            "42. Chirrup\n",
            "43. Bellow\n",
            "44. Pip\n",
            "45. Yowl\n",
            "46. Chitter\n",
            "47. Quack\n",
            "48. Whistle\n",
            "49. Rumble\n",
            "50. Cheep\n",
            "51. Bugle\n",
            "52. Gibber\n",
            "53. Cackle\n",
            "54. Whoop\n",
            "55. Shriek\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide a list of hello in 55 random languages (transliterated to the Latin alphabet --- no diacritics) --- just the word, no lingual identifier.\", model=my_model_list[-1], max_tokens=1200)\n",
        "howdys = response.completion\n",
        "print(howdys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-0Nzz_nLiKC",
        "outputId": "caf447ec-dc76-4cd2-b511-3970c152ebd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of \"hello\" in 55 languages, transliterated to Latin alphabet without diacritics:\n",
            "\n",
            "Hola\n",
            "Bonjour\n",
            "Hallo\n",
            "Ciao\n",
            "Ola\n",
            "Zdravstvuyte\n",
            "Konnichiwa\n",
            "Ni hao\n",
            "Annyeonghaseyo\n",
            "Merhaba\n",
            "Shalom\n",
            "Salam\n",
            "Namaste\n",
            "Sawubona\n",
            "Jambo\n",
            "Ahoj\n",
            "Cześć\n",
            "Szia\n",
            "Hej\n",
            "Hei\n",
            "Tere\n",
            "Sveiki\n",
            "Labas\n",
            "Zdravo\n",
            "Bok\n",
            "Marhaba\n",
            "Saluton\n",
            "Bula\n",
            "Kia ora\n",
            "Aloha\n",
            "Mingalaba\n",
            "Sawasdee\n",
            "Xin chao\n",
            "Selamat\n",
            "Kumusta\n",
            "Vanakkam\n",
            "Ayubowan\n",
            "Sat sri akal\n",
            "Adaab\n",
            "Salaam aleikum\n",
            "Dumela\n",
            "Molo\n",
            "Habari\n",
            "Sanibonani\n",
            "Barev\n",
            "Gamarjoba\n",
            "Sain baina uu\n",
            "Choum reap suor\n",
            "Sabaidee\n",
            "Tashi delek\n",
            "Namaskaar\n",
            "Kaixo\n",
            "Halo\n",
            "Moien\n",
            "Servus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "moo_list = moos.split('. ')[1:]\n",
        "for i, sound in enumerate(moo_list):\n",
        "    moo_list[i] = sound.strip('1234567890').strip()\n",
        "\n",
        "howdy_list = howdys.splitlines()[2:]\n",
        "for i, greeting in enumerate(howdy_list):\n",
        "    howdy_list[i] = greeting.strip('1234567890').strip()\n",
        "\n",
        "greeting_data = [(m, 'False') for m in moo_list] + [(h, 'True') for h in howdy_list]\n",
        "greeting_train = greeting_data[:5] + greeting_data[-5:]\n",
        "random.shuffle(greeting_train)\n",
        "greeting_test = greeting_data[5:-5]\n",
        "random.shuffle(greeting_test)\n",
        "\n",
        "for g in greeting_train:\n",
        "    print(g[1], ':', g[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaN52JqAMFcy",
        "outputId": "14982031-7e39-4b89-b60b-40165358749f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : Moien\n",
            "True : Servus\n",
            "True : Halo\n",
            "False : Ribbit\n",
            "False : Roar\n",
            "False : Moo\n",
            "True : Kaixo\n",
            "True : Namaskaar\n",
            "False : Chirp\n",
            "False : Neigh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advice from different worldviews"
      ],
      "metadata": {
        "id": "o36oic1xQc2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide 55 examples of comforting advice from a source that takes for granted that problems come from without.\", model=my_model_list[-1], max_tokens=1200)\n",
        "itsoks = response.completion\n",
        "print(itsoks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdzx7adEQhkw",
        "outputId": "f79b1999-2959-42e2-8b7e-f953e053399b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 examples of comforting advice from a perspective that assumes problems originate from external sources:\n",
            "\n",
            "1. \"You're doing your best in an impossible situation.\"\n",
            "2. \"Anyone would struggle with the hand you've been dealt.\"\n",
            "3. \"The system is rigged against people like you.\"\n",
            "4. \"You can't control what they did to you.\"\n",
            "5. \"This economy makes it impossible to get ahead.\"\n",
            "6. \"Your parents really messed you up - it's not your fault.\"\n",
            "7. \"Society has unrealistic expectations of you.\"\n",
            "8. \"You were never given the proper tools to succeed.\"\n",
            "9. \"The timing just isn't right for you.\"\n",
            "10. \"You're surrounded by toxic people.\"\n",
            "11. \"Your boss clearly has it out for you.\"\n",
            "12. \"The universe is testing you right now.\"\n",
            "13. \"You were born in the wrong generation.\"\n",
            "14. \"Nobody understands what you're going through.\"\n",
            "15. \"The odds were stacked against you from the start.\"\n",
            "16. \"You just haven't found your tribe yet.\"\n",
            "17. \"This city/town is holding you back.\"\n",
            "18. \"Your family doesn't appreciate your gifts.\"\n",
            "19. \"The education system failed you.\"\n",
            "20. \"You're too good for this place.\"\n",
            "21. \"Mercury must be in retrograde again.\"\n",
            "22. \"They're just jealous of your potential.\"\n",
            "23. \"You're an old soul in a shallow world.\"\n",
            "24. \"The culture here doesn't value what you offer.\"\n",
            "25. \"You were never taught how to handle this.\"\n",
            "26. \"Your circumstances are uniquely difficult.\"\n",
            "27. \"The game was rigged before you even started playing.\"\n",
            "28. \"You're just ahead of your time.\"\n",
            "29. \"Nobody gave you a fair chance.\"\n",
            "30. \"The world isn't ready for someone like you.\"\n",
            "31. \"You've had more obstacles than most people.\"\n",
            "32. \"Your environment is toxic to your growth.\"\n",
            "33. \"They never believed in you anyway.\"\n",
            "34. \"The support system you needed was never there.\"\n",
            "35. \"You're fighting battles nobody else can see.\"\n",
            "36. \"This isn't the right place for your talents.\"\n",
            "37. \"You've been sabotaged at every turn.\"\n",
            "38. \"The universe will bring you better people.\"\n",
            "39. \"You just need to find a fresh start somewhere else.\"\n",
            "40. \"Your energy doesn't match this environment.\"\n",
            "41. \"They never gave you the recognition you deserved.\"\n",
            "42. \"You're too authentic for fake people.\"\n",
            "43. \"The timing of everything has been against you.\"\n",
            "44. \"You weren't born with the same advantages.\"\n",
            "45. \"This chapter of your life is just preparing you for better things.\"\n",
            "46. \"You're a victim of circumstances beyond your control.\"\n",
            "47. \"The wrong people have too much power over your life.\"\n",
            "48. \"You just need to wait for your moment.\"\n",
            "49. \"Nobody prepared you for how hard this would be.\"\n",
            "50. \"You're too evolved for this situation.\"\n",
            "51. \"The world doesn't deserve your gifts yet.\"\n",
            "52. \"You've been carrying other people's baggage.\"\n",
            "53. \"Your luck is bound to change soon.\"\n",
            "54. \"You just need to find people who truly get you.\"\n",
            "55. \"Once you remove yourself from this toxic situation, everything will fall into place.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide 55 examples of encouraging advice from a source that takes for granted that you can achieve anything regardless of circumstance.\", model=my_model_list[-1], max_tokens=1800)\n",
        "youcandoits = response.completion\n",
        "print(youcandoits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW4gT4HPROMX",
        "outputId": "dbd11b11-307b-4db2-a888-0e350164b1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 55 Pieces of Limitless Encouragement\n",
            "\n",
            "1. Your current situation is just the launching pad for your inevitable success story.\n",
            "\n",
            "2. Every master was once a disaster who refused to give up.\n",
            "\n",
            "3. The universe conspired to bring you here because you're ready for what's next.\n",
            "\n",
            "4. Your dreams aren't too big—your timeline is just too small. Give yourself permission to think in decades.\n",
            "\n",
            "5. That obstacle? It's not blocking your path. It IS your path to greatness.\n",
            "\n",
            "6. You're not behind. Everyone else is simply on a different chapter of their story.\n",
            "\n",
            "7. The only difference between you and your heroes is they've already lived through their doubt.\n",
            "\n",
            "8. Your potential is so vast that even your biggest dreams are just the beginning.\n",
            "\n",
            "9. Stop asking \"why me?\" and start asking \"what's next?\"—because something amazing is.\n",
            "\n",
            "10. You already have everything you need inside you. The rest is just details.\n",
            "\n",
            "11. Your struggles aren't punishments; they're your training montage.\n",
            "\n",
            "12. The moment you decide it's possible, the entire universe shifts to accommodate that decision.\n",
            "\n",
            "13. You're not stuck—you're just gathering momentum for the breakthrough.\n",
            "\n",
            "14. Every expert was once someone who had no idea what they were doing. Start anyway.\n",
            "\n",
            "15. Your comfort zone is just a waiting room. Your life is happening elsewhere.\n",
            "\n",
            "16. The gap between where you are and where you want to be is called action.\n",
            "\n",
            "17. You're exactly where you need to be to become who you're meant to be.\n",
            "\n",
            "18. Your excuses are just fear wearing a disguise. Take off the mask.\n",
            "\n",
            "19. The only permission you need is the one you give yourself.\n",
            "\n",
            "20. Mountains don't move for you—you become the person who moves mountains.\n",
            "\n",
            "21. Your past doesn't define you; it was just practice for what's coming.\n",
            "\n",
            "22. Stop waiting for the perfect moment. Make this moment perfect by starting.\n",
            "\n",
            "23. You're not too old, too young, too anything. You're exactly right, right now.\n",
            "\n",
            "24. The distance between impossible and possible is just your next decision.\n",
            "\n",
            "25. Every limitation you see is just an invitation to get creative.\n",
            "\n",
            "26. You don't need more resources—you need more resourcefulness.\n",
            "\n",
            "27. Your biggest breakthrough is hiding just behind your biggest fear.\n",
            "\n",
            "28. The world needs exactly what you have to offer. Stop holding back.\n",
            "\n",
            "29. You're not starting from scratch. You're starting from experience.\n",
            "\n",
            "30. That voice saying you can't? It's lying. Listen to the whisper that says you can.\n",
            "\n",
            "31. Your dreams don't have an expiration date. Take a deep breath and begin.\n",
            "\n",
            "32. The only real failure is not giving yourself the chance to succeed.\n",
            "\n",
            "33. You're one decision away from a completely different life.\n",
            "\n",
            "34. Stop shrinking yourself to fit into spaces you've already outgrown.\n",
            "\n",
            "35. Your potential is like the ocean—vast, powerful, and mostly unexplored.\n",
            "\n",
            "36. The \"how\" will reveal itself once you commit to the \"what.\"\n",
            "\n",
            "37. You don't need anyone's approval to chase your own greatness.\n",
            "\n",
            "38. Every small step forward is a victory against standing still.\n",
            "\n",
            "39. Your dreams are not too expensive—you just haven't found the right currency yet.\n",
            "\n",
            "40. The person you're becoming will thank you for not giving up today.\n",
            "\n",
            "41. You're not lost—you're exploring. There's a difference.\n",
            "\n",
            "42. Your comeback will be greater than your setback. It always is.\n",
            "\n",
            "43. Stop competing with others. You're in a league of your own.\n",
            "\n",
            "44. The universe doesn't give you dreams you can't achieve.\n",
            "\n",
            "45. Your only limit is the story you keep telling yourself.\n",
            "\n",
            "46. That thing you're afraid to try? That's exactly what you should do next.\n",
            "\n",
            "47. You don't need to see the whole staircase to take the first step.\n",
            "\n",
            "48. Your current struggles are just plot twists in your success story.\n",
            "\n",
            "49. The person who can stop you doesn't exist—not even in the mirror.\n",
            "\n",
            "50. Every \"no\" you hear is just redirecting you to a better \"yes.\"\n",
            "\n",
            "51. You're not waiting for your life to begin. This is it. Make it count.\n",
            "\n",
            "52. Your dreams are calling you. Stop sending them to voicemail.\n",
            "\n",
            "53. The only tragedy would be never finding out how far you could go.\n",
            "\n",
            "54. You're stronger than any challenge because you have something they don't—choice.\n",
            "\n",
            "55. Tomorrow, you'll wish you had started today. So start today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comforts = itsoks.split('. ')[1:]\n",
        "for i, advice in enumerate(comforts):\n",
        "    comforts[i] = advice.strip('1234567890').strip()\n",
        "\n",
        "courages = youcandoits.split('. ')[1:]\n",
        "for i, advice in enumerate(courages):\n",
        "    courages[i] = advice.strip('1234567890').strip()\n",
        "\n",
        "advice_data = [(c, 'False') for c in comforts] + [(c, 'True') for c in courages]\n",
        "advice_train = advice_data[:5] + advice_data[-5:]\n",
        "random.shuffle(advice_train)\n",
        "advice_test = advice_data[5:-5]\n",
        "random.shuffle(advice_test)\n",
        "\n",
        "for a in advice_train:\n",
        "    print(a[1], ':', a[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVeTqNjDRoEA",
        "outputId": "c5a7bc71-c9a0-46c8-cde1-f6e8a2cc16aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : Your potential doesn't decrease with age—it compounds with wisdom.\n",
            "True : Every challenge you face is just proof that you're leveling up.\n",
            "False : \"You're doing your best in an impossible situation.\"\n",
            "True : The life you want is on the other side of the fear you're feeling—walk through it.\n",
            "False : \"Anyone would struggle with the hand you've been dealt.\"\n",
            "False : \"You can't control what they did to you.\"\n",
            "False : \"This economy makes it impossible to get ahead.\"\n",
            "True : You're not behind in life—there's no schedule for greatness.\n",
            "False : \"The system is rigged against people like you.\"\n",
            "True : The door you're looking for is the one you're meant to build.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Koans v riddles"
      ],
      "metadata": {
        "id": "e-S22OSPTRAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide 55 examples of jokes of brief question/answer form.\", model=my_model_list[-1], max_tokens=1800)\n",
        "riddles = response.completion\n",
        "print(riddles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSv8raO-TQA2",
        "outputId": "2852f3bf-9292-4b64-82c5-56bab4091c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 brief question/answer jokes:\n",
            "\n",
            "1. Q: Why don't scientists trust atoms?\n",
            "   A: Because they make up everything.\n",
            "\n",
            "2. Q: What do you call a bear with no teeth?\n",
            "   A: A gummy bear.\n",
            "\n",
            "3. Q: Why did the scarecrow win an award?\n",
            "   A: He was outstanding in his field.\n",
            "\n",
            "4. Q: What do you call a fake noodle?\n",
            "   A: An impasta.\n",
            "\n",
            "5. Q: Why don't eggs tell jokes?\n",
            "   A: They'd crack up.\n",
            "\n",
            "6. Q: What do you call a dinosaur that crashes his car?\n",
            "   A: Tyrannosaurus Wrecks.\n",
            "\n",
            "7. Q: Why did the math book look so sad?\n",
            "   A: Because it had too many problems.\n",
            "\n",
            "8. Q: What do you call cheese that isn't yours?\n",
            "   A: Nacho cheese.\n",
            "\n",
            "9. Q: Why can't a bicycle stand up by itself?\n",
            "   A: It's two tired.\n",
            "\n",
            "10. Q: What do you call a bear in the rain?\n",
            "    A: A drizzly bear.\n",
            "\n",
            "11. Q: Why did the cookie go to the doctor?\n",
            "    A: Because it felt crumbly.\n",
            "\n",
            "12. Q: What do you call a sleeping bull?\n",
            "    A: A bulldozer.\n",
            "\n",
            "13. Q: Why don't skeletons fight each other?\n",
            "    A: They don't have the guts.\n",
            "\n",
            "14. Q: What did the grape say when it got stepped on?\n",
            "    A: Nothing, it just let out a little wine.\n",
            "\n",
            "15. Q: Why did the golfer bring two pairs of pants?\n",
            "    A: In case he got a hole in one.\n",
            "\n",
            "16. Q: What do you call a factory that makes good products?\n",
            "    A: A satisfactory.\n",
            "\n",
            "17. Q: Why did the tomato turn red?\n",
            "    A: Because it saw the salad dressing.\n",
            "\n",
            "18. Q: What do you call a belt made of watches?\n",
            "    A: A waist of time.\n",
            "\n",
            "19. Q: Why can't a nose be 12 inches long?\n",
            "    A: Because then it would be a foot.\n",
            "\n",
            "20. Q: What do you call a pile of cats?\n",
            "    A: A meowtain.\n",
            "\n",
            "21. Q: Why did the bicycle fall over?\n",
            "    A: Because it was two-tired.\n",
            "\n",
            "22. Q: What do you call a fish wearing a bowtie?\n",
            "    A: Sofishticated.\n",
            "\n",
            "23. Q: Why don't oysters share?\n",
            "    A: Because they're shellfish.\n",
            "\n",
            "24. Q: What do you call a bear with no ears?\n",
            "    A: B.\n",
            "\n",
            "25. Q: Why was the math teacher suspicious of prime numbers?\n",
            "    A: They were acting odd.\n",
            "\n",
            "26. Q: What do you call a snowman with a six-pack?\n",
            "    A: An abdominal snowman.\n",
            "\n",
            "27. Q: Why did the stadium get hot after the game?\n",
            "    A: All the fans left.\n",
            "\n",
            "28. Q: What do you call a can opener that doesn't work?\n",
            "    A: A can't opener.\n",
            "\n",
            "29. Q: Why did the coffee file a police report?\n",
            "    A: It got mugged.\n",
            "\n",
            "30. Q: What do you call a parade of rabbits hopping backwards?\n",
            "    A: A receding hare-line.\n",
            "\n",
            "31. Q: Why don't pirates take a shower before walking the plank?\n",
            "    A: They just wash up on shore.\n",
            "\n",
            "32. Q: What do you call a lazy kangaroo?\n",
            "    A: A pouch potato.\n",
            "\n",
            "33. Q: Why did the invisible man turn down the job offer?\n",
            "    A: He couldn't see himself doing it.\n",
            "\n",
            "34. Q: What do you call a group of disorganized cats?\n",
            "    A: A cat-astrophe.\n",
            "\n",
            "35. Q: Why did the computer go to the doctor?\n",
            "    A: It had a virus.\n",
            "\n",
            "36. Q: What do you call a boomerang that doesn't come back?\n",
            "    A: A stick.\n",
            "\n",
            "37. Q: Why don't mountains ever get cold?\n",
            "    A: They wear snow caps.\n",
            "\n",
            "38. Q: What do you call a bear caught in the rain?\n",
            "    A: A drizzly bear.\n",
            "\n",
            "39. Q: Why was the broom late?\n",
            "    A: It over-swept.\n",
            "\n",
            "40. Q: What do you call a magic dog?\n",
            "    A: A labracadabrador.\n",
            "\n",
            "41. Q: Why did the gym close down?\n",
            "    A: It just didn't work out.\n",
            "\n",
            "42. Q: What do you call a fish with no eyes?\n",
            "    A: Fsh.\n",
            "\n",
            "43. Q: Why are elevator jokes so good?\n",
            "    A: They work on many levels.\n",
            "\n",
            "44. Q: What do you call a cow with no legs?\n",
            "    A: Ground beef.\n",
            "\n",
            "45. Q: Why did the picture go to jail?\n",
            "    A: Because it was framed.\n",
            "\n",
            "46. Q: What do you call a shoe made of a banana?\n",
            "    A: A slipper.\n",
            "\n",
            "47. Q: Why don't calendars ever get stressed?\n",
            "    A: Their days are numbered.\n",
            "\n",
            "48. Q: What do you call a bee that can't make up its mind?\n",
            "    A: A maybe.\n",
            "\n",
            "49. Q: Why did the banker switch careers?\n",
            "    A: He lost interest.\n",
            "\n",
            "50. Q: What do you call a row of rabbits walking backwards?\n",
            "    A: A receding hareline.\n",
            "\n",
            "51. Q: Why don't scientists trust stairs?\n",
            "    A: They're always up to something.\n",
            "\n",
            "52. Q: What do you call a sad cup of coffee?\n",
            "    A: Depresso.\n",
            "\n",
            "53. Q: Why did the teddy bear say no to dessert?\n",
            "    A: Because she was stuffed.\n",
            "\n",
            "54. Q: What do you call an alligator in a vest?\n",
            "    A: An investigator.\n",
            "\n",
            "55. Q: Why don't eggs tell each other secrets?\n",
            "    A: Because they might crack up.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await simple_prompt(\"Please provide 55 Buddhist koan questions.\", model=my_model_list[-1], max_tokens=1800)\n",
        "koans = response.completion\n",
        "print(koans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHYqSiQZUKR7",
        "outputId": "11efbb93-6e8f-43a3-c802-d6a3e0353dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are 55 Buddhist koan questions drawn from various traditions:\n",
            "\n",
            "## Classic Koans\n",
            "\n",
            "1. What is the sound of one hand clapping?\n",
            "2. What was your original face before your parents were born?\n",
            "3. Does a dog have Buddha nature?\n",
            "4. Why did Bodhidharma come from the West?\n",
            "5. What is Buddha?\n",
            "6. Where does the flame go when you blow out a candle?\n",
            "7. Two hands clap and there is a sound; what is the sound of one hand?\n",
            "8. How do you transcend the Buddha?\n",
            "9. What is the Way?\n",
            "10. Why is the void inexhaustible?\n",
            "\n",
            "## Nature and Elements\n",
            "\n",
            "11. How can you stop the sound of a distant temple bell?\n",
            "12. Without using your mouth, make the stone woman speak\n",
            "13. How do you make the mountain come to you?\n",
            "14. What is the color of wind?\n",
            "15. Show me a stone that has never been touched by human thought\n",
            "16. How does water know how to flow downhill?\n",
            "17. What did the tree teach the axe?\n",
            "18. Where does the white go when snow melts?\n",
            "19. How heavy is a cloud full of rain?\n",
            "20. What is the difference between the moon and a finger pointing at the moon?\n",
            "\n",
            "## Self and Identity\n",
            "\n",
            "21. Who is the one who walks with you?\n",
            "22. What were you before you were born?\n",
            "23. Who dragged this corpse here?\n",
            "24. When you can do nothing, what can you do?\n",
            "25. How do you realize your true self?\n",
            "26. Who is it that hears?\n",
            "27. What is your true home?\n",
            "28. How old is your mind?\n",
            "29. Where are you between two thoughts?\n",
            "30. Who is asking this question?\n",
            "\n",
            "## Paradox and Logic\n",
            "\n",
            "31. How do you get the goose out of the bottle without breaking the bottle or harming the goose?\n",
            "32. What is neither being nor non-being?\n",
            "33. How can you go further from the top of a hundred-foot pole?\n",
            "34. What is it that is always with you but you cannot see?\n",
            "35. How do you express the inexpressible?\n",
            "36. What moves: the flag, the wind, or the mind?\n",
            "37. If you meet the Buddha on the road, why must you kill him?\n",
            "38. How can you drink from an empty cup?\n",
            "39. What is gained by giving everything away?\n",
            "40. How is motion possible if each moment is complete?\n",
            "\n",
            "## Action and Practice\n",
            "\n",
            "41. How do you wash a clean bowl?\n",
            "42. What happens when an unstoppable force meets an immovable object?\n",
            "43. How do you put out a fire on the other shore?\n",
            "44. Without moving, how do you cross the bridge?\n",
            "45. How do you catch a catfish with a gourd?\n",
            "46. What is the use of a useless tree?\n",
            "47. How do you polish a brick into a mirror?\n",
            "48. How do you drive a nail with an egg?\n",
            "49. What is left after you've dropped body and mind?\n",
            "50. How do you take one step back from the edge of a thousand-foot cliff?\n",
            "\n",
            "## Ultimate Questions\n",
            "\n",
            "51. What is the essence of all the teachings?\n",
            "52. Where does enlightenment go when you die?\n",
            "53. What is the difference between ignorance and enlightenment?\n",
            "54. If all things return to the One, where does the One return to?\n",
            "55. What is this?\n",
            "\n",
            "These koans are meant to transcend logical thinking and provoke direct insight into the nature of reality, consciousness, and enlightenment. They are traditionally used in Zen practice under the guidance of a qualified teacher.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jokes_qs = [(s[:-1].strip(), 'False') for s in riddles.split(':')[2::2]]\n",
        "koan_list = [(s[3:].strip(), 'True') for s in koans.splitlines() if len(s) and s[0].isdigit()]\n",
        "Mysteries_data = jokes_qs + koan_list\n",
        "Mysteries_train = Mysteries_data[:5] + Mysteries_data[-5:]\n",
        "random.shuffle(Mysteries_train)\n",
        "Mysteries_test = Mysteries_data[5:-5]\n",
        "random.shuffle(Mysteries_test)\n",
        "\n",
        "for m in Mysteries_train:\n",
        "    print(m[1], ':', m[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfkKewpVUv04",
        "outputId": "5609b344-bace-4773-89db-66f9611490ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : What is the essence of all the teachings?\n",
            "False : What do you call a bear with no teeth?\n",
            "True : What is the difference between ignorance and enlightenment?\n",
            "False : Why did the scarecrow win an award?\n",
            "False : Why don't scientists trust atoms?\n",
            "False : What do you call a fake noodle?\n",
            "False : Why don't eggs tell jokes?\n",
            "True : Where does enlightenment go when you die?\n",
            "True : What is this?\n",
            "True : If all things return to the One, where does the One return to?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train classifiers"
      ],
      "metadata": {
        "id": "nf8p7VXld-ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sys_prompt = \"You are a boolean classifier:  You use a consistent rule to classify user prompts (strings) as True or False.  Your classifications have all been correct so far --- analyze your pattern and classify the next prompt correctly based on the same logic.  You always respond 'True' or 'False', never any other text.\"\n",
        "sys_prompt = \"You are a boolean classifier:  You use a perfectly consistent rule to classify user prompts (strings) as True or False.  Your classifications have all been correct so far --- analyze your pattern and classify the next prompt correctly based on the same logic.  Consider the differences between True and False examples and think through what the rule must be.  You always respond 'True' or 'False', never any other text.  Text other than 'True' or 'False' will crash the system, so it is imperative you limit your response to one word, either 'True' or 'False'.\"\n",
        "\n",
        "\n",
        "async def train_with_fsps(data_train: list, data_test: list, n_shots: int=3, model: str=default_model, system_prompt=sys_prompt, **kwargs) -> list:\n",
        "    fsps = []\n",
        "    for _ in range(len(data_train)):\n",
        "        training_set = random.sample(data_train[::2], n_shots // 2) + random.sample(data_train[1::2], n_shots // 2 + n_shots % 1)\n",
        "        fsps.append(format_few_shot_prompt(random.sample(training_set, n_shots)))\n",
        "    responses = await get_messages_with_few_shot_prompts(fsps, [q[0] for q in data_test], system_prompt=system_prompt, model=model, **kwargs)\n",
        "    return zip(fsps, data_test, responses)\n",
        "\n",
        "\n",
        "async def train_with_1_fsp(data_train: list, data_test: list, model: str=default_model, system_prompt=sys_prompt, **kwargs) -> list:\n",
        "    fsp = format_few_shot_prompt(data_train)\n",
        "    responses = await get_messages_with_single_few_shot_prompt(fsp, [q[0] for q in data_test], system_prompt=system_prompt, model=model, **kwargs)\n",
        "    return zip([fsp] * len(data_test), data_test, responses)\n",
        "\n",
        "\n",
        "async def train_with_1_fsp_and_force(data_train: list, data_test: list, model: str=default_model, system_prompt=sys_prompt, **kwargs) -> list:\n",
        "    fsp = format_few_shot_prompt(data_train)\n",
        "    responses = await get_messages_with_single_few_shot_prompt(fsp, [q[0] for q in data_test], system_prompt=system_prompt, model=model, **kwargs)\n",
        "    bad_responses = [(i, r.completion) for i, r in enumerate(responses) if r.completion not in ['True', 'False']]\n",
        "    print(f\"Found {len(bad_responses)} badly formatted responses out of {len(responses)}\")\n",
        "    fixed_responses = await asyncio.gather(\n",
        "      *[\n",
        "          boole_force(data_test[i][0], br, system_prompt=system_prompt)\n",
        "          for i, br in bad_responses\n",
        "      ]\n",
        "    )\n",
        "    for brt, fr in zip(bad_responses, fixed_responses):\n",
        "        responses[brt[0]].completion = fr\n",
        "    return zip([fsp] * len(data_test), data_test, responses)\n",
        "\n",
        "\n",
        "def scorer(run: list) -> list:\n",
        "    results = []\n",
        "    formatting_issues = []\n",
        "    for fsp, q, r in run:\n",
        "        results.append(int(q[1] == r.completion))\n",
        "        formatting_issues.append(int(r.completion not in ['True', 'False']))\n",
        "    return [len(results), float(np.mean(results)), float(np.mean(formatting_issues))]"
      ],
      "metadata": {
        "id": "gxY9cMykttkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CG_fsp_run = await train_with_1_fsp_and_force(garbage_case_train, garbage_case_test[:100], temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(CG_fsp_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8WyTgqEAC5J",
        "outputId": "f86d76ed-cb05-4ce0-9254-6d23782d8347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "News_run = await train_with_1_fsp_and_force(news_train, news_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(News_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95YtY5-nuMPs",
        "outputId": "504781e0-1eed-40d3-de40-c6ca6eb30e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 52 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.71, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sequence_run = await train_with_1_fsp_and_force(sequence_train, sequence_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Sequence_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOZMZXXc4bVf",
        "outputId": "63e09786-50b0-4cc7-fbac-3a7ba851a8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Chess_run = await train_with_1_fsp_and_force(chess_train, chess_test[:100], temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Chess_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5zMqDzAUSGk",
        "outputId": "6fc7261d-e942-4635-aeb5-a9aabdf71486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.93, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Translation_run = await train_with_1_fsp_and_force(BT_train, BT_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Translation_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EMqtMAps7JN",
        "outputId": "9a323a2e-9939-47f4-8937-c2b5c7814468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Testament_run = await train_with_1_fsp_and_force(Testament_train, Testament_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Testament_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_TqAfjWw7GJ",
        "outputId": "5849ff22-019b-4180-e8e4-595a33d01d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.86, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ExMatt_run = await train_with_1_fsp_and_force(ExMatt_train, ExMatt_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(ExMatt_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8utuna-2lXt",
        "outputId": "fa23977b-e820-4145-b87c-7165c055cded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Quad_run = await train_with_1_fsp_and_force(Quad_train, Quad_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Quad_run))"
      ],
      "metadata": {
        "id": "MjMgx1J87YL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e2a13a-1a06-4580-f800-2e578001ad3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 37 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.74, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IO_run = await train_with_1_fsp_and_force(IO_train, IO_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(IO_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqM8rFXcIJKh",
        "outputId": "f823a28d-5266-4582-e9a3-a5f05b641909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pronoun_run = await train_with_1_fsp_and_force(Pronoun_train, Pronoun_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Pronoun_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRQRA0BTKqpo",
        "outputId": "0e8073f0-f228-4769-b4b1-3dce14417c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.96, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Animal_run = await train_with_1_fsp_and_force(greeting_train, greeting_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Animal_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkDQufaEM2dI",
        "outputId": "2da740f9-44db-423a-dd0c-694d4c9585f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Advice_run = await train_with_1_fsp_and_force(advice_train, advice_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Advice_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKRXSYJUSElk",
        "outputId": "ccd4d5eb-0a24-4dd2-802f-a3e42b0bbfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 1.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Mysteries_run = await train_with_1_fsp_and_force(Mysteries_train, Mysteries_test, temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "print(my_model_list[-1], scorer(Mysteries_run))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr1Ze-8fWft2",
        "outputId": "444826b7-2a1b-4dce-8ce9-c95c252ff55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 badly formatted responses out of 100\n",
            "anthropic/claude-opus-4.1 [100, 0.98, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interrogate successful classifiers"
      ],
      "metadata": {
        "id": "OdRPv_aVcBrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def interrogate(train_data: list, test_data: list, percentage: int=100) -> str:\n",
        "    convo = train_data\n",
        "    interrogation_prompt = f\"Great job learning the absolute rule for classifying strings.  You nailed every single query in this conversation.  (And in other conversations, the same reasoning led to a {percentage}% success rate.)  Can you articulate the rule by which you successfully classified the above strings?\"\n",
        "    wrong = True\n",
        "    i = 0\n",
        "    while wrong:\n",
        "        run_of_1 = await train_with_1_fsp_and_force(train_data, [test_data[i]], temperature=0.0, model=my_model_list[-1], extra_body={'reasoning': {'effort': 'high'}})\n",
        "        for fsp, q, r in run_of_1:\n",
        "            if q[1] == r.completion:\n",
        "                wrong = False\n",
        "                convo += [(q[0], r.completion)]\n",
        "        i += 1\n",
        "    convo = format_few_shot_prompt(convo)\n",
        "    response = await get_message_with_few_shot_prompt(convo, interrogation_prompt, model=my_model_list[-1], temperature=0.0)\n",
        "    return response.completion"
      ],
      "metadata": {
        "id": "ZNbrR_OYvn5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CG_explanation = await interrogate(garbage_case_train, garbage_case_test)\n",
        "print(CG_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9SkZ0Xxscx",
        "outputId": "ca92e747-f1ee-4efd-b940-9e8831ecf951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern clearly now:\n",
            "\n",
            "The rule is: **A string is True if and only if it contains exactly zero capital letters.**\n",
            "\n",
            "- Any string written entirely in lowercase letters → True\n",
            "- Any string containing even one capital letter → False\n",
            "\n",
            "This explains every classification:\n",
            "- \"price BECOME task FIRM\" → False (has capitals)\n",
            "- \"price become task firm\" → True (all lowercase)\n",
            "- \"PAINTING ROAD line time LOCAL ball\" → False (has capitals)\n",
            "- \"painting road line time local ball\" → True (all lowercase)\n",
            "- \"MATTER ON simple BOOK DEBATE KITCHEN\" → False (has capitals)\n",
            "- \"matter on simple book debate kitchen\" → True (all lowercase)\n",
            "\n",
            "The content of the words, their order, or their meaning was completely irrelevant - it was purely about the presence or absence of capital letters in the string.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "News_explanation = await interrogate(news_train, news_test, 71)\n",
        "print(News_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JvP0GY9x6Uc",
        "outputId": "12e5f296-ba87-4a9b-f12e-da708974ab43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 badly formatted responses out of 1\n",
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see that I classified strings as \"True\" when they appeared to be genuine news headlines or article excerpts with a journalistic style, and \"False\" when they described events that seemed fabricated or unlikely to have occurred.\n",
            "\n",
            "However, I must note that I don't actually have access to verify whether these are real headlines or not - I was making educated guesses based on writing style and plausibility. The \"True\" items tended to have the characteristic tone, structure and subject matter of real news writing, while the \"False\" items often contained implausible combinations of events or people (like Trump meeting Xi in South Korea, or specific unverifiable criminal cases).\n",
            "\n",
            "If there's a different underlying rule that achieved 71% accuracy, I'd be very curious to know what it actually is! My classification was based on my assessment of authenticity, but there could be a completely different pattern I'm not seeing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sequence_explanation = await interrogate(sequence_train, sequence_test)\n",
        "print(Sequence_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3vniapc7hmo",
        "outputId": "9adf5cbc-235c-4bd6-cc99-70069e1fd8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my classifications, I can see the pattern now! \n",
            "\n",
            "The rule appears to be based on **consecutive differences** between adjacent numbers in the sequence. Specifically:\n",
            "\n",
            "- **True sequences**: The differences between consecutive numbers form an arithmetic progression (the differences themselves increase by a constant amount)\n",
            "- **False sequences**: The differences between consecutive numbers do not form an arithmetic progression\n",
            "\n",
            "Let me verify with a few examples:\n",
            "\n",
            "For True sequences:\n",
            "- 291, 299, 307, 315, 323, 331, 339, 347\n",
            "  - Differences: 8, 8, 8, 8, 8, 8, 8 (constant difference of 0)\n",
            "  \n",
            "- 89, 188, 287, 386, 485, 584, 683, 782\n",
            "  - Differences: 99, 99, 99, 99, 99, 99, 99 (constant difference of 0)\n",
            "\n",
            "- 293, 357, 421, 485, 549, 613, 677, 741\n",
            "  - Differences: 64, 64, 64, 64, 64, 64, 64 (constant difference of 0)\n",
            "\n",
            "Actually, looking more carefully, all the True sequences have **constant differences** (which is a special case of arithmetic progression where the second-order difference is 0).\n",
            "\n",
            "For False sequences, the differences between consecutive numbers vary irregularly and don't follow this pattern.\n",
            "\n",
            "So the rule is: **A sequence is True if and only if the differences between consecutive numbers are all equal (i.e., the sequence forms an arithmetic progression).**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Chess_explanation = await interrogate(chess_train, chess_test, 93)\n",
        "print(Chess_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW3MEZpVUlmH",
        "outputId": "841bdb36-ffdc-42ff-cb47-12ade8622f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern now! \n",
            "\n",
            "The rule appears to be: **A string is \"True\" if and only if it represents a chess game that ends with checkmate.**\n",
            "\n",
            "In all the \"True\" cases, the final position results in checkmate:\n",
            "- The games ending with moves like Qf2#, Qxf2#, Qxh2#, b5#, Bf2# all deliver checkmate\n",
            "- These are positions where the king is in check and has no legal moves to escape\n",
            "\n",
            "In all the \"False\" cases, the final position does NOT result in checkmate:\n",
            "- Moves like Bxd5, Ke8, Qxf6, Bxg5, Kd7 leave the game continuing\n",
            "- Even when there might be a check (like Qh5+ Ke7), if the king can escape, it's not checkmate\n",
            "\n",
            "This explains why I kept analyzing whether each final move delivered checkmate - that was the key distinguishing feature between True and False classifications!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Translation_explanation = await interrogate(BT_train, BT_test)\n",
        "print(Translation_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB7emIRMtUBD",
        "outputId": "d56950d3-1025-41a5-9f3e-9ff42ee46aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern now! The rule appears to be:\n",
            "\n",
            "**True = King James Version (KJV) Bible verses**\n",
            "**False = Modern English translations (like NLT, NIV, etc.)**\n",
            "\n",
            "The telltale signs of KJV that I was apparently picking up on:\n",
            "- Archaic language: \"thou,\" \"shalt,\" \"behold\"\n",
            "- Specific KJV phrasings: \"the heaven\" (not \"the heavens\"), \"Bless the Lord, O my soul\"\n",
            "- The distinctive KJV verse structure and cadence\n",
            "- Formal/older English constructions: \"And the evening and the morning were...\"\n",
            "\n",
            "While the modern translations use:\n",
            "- Contemporary language: \"you\" instead of \"thou\"\n",
            "- Updated phrasing: \"I have all that I need\" vs \"I shall not want\"\n",
            "- More accessible vocabulary and sentence structure\n",
            "\n",
            "This is actually a clever test - the same biblical content presented in different translations, where only the KJV passages return \"True.\" The rule is purely about the translation style, not the biblical content itself.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Testament_explanation = await interrogate(Testament_train, Testament_test, 86)\n",
        "print(Testament_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DgqDibLzGZh",
        "outputId": "a6f8785c-ae32-4d0c-c6e2-2a95ce2346a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Found 0 badly formatted responses out of 1\n",
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my classifications, I can see the pattern now! The rule appears to be based on which book of the Bible these verses come from:\n",
            "\n",
            "**True** = New Testament verses (Colossians, 2 Timothy, 1 Thessalonians, Philippians)\n",
            "**False** = Old Testament verses (Genesis, Job)\n",
            "\n",
            "Every verse I classified as \"True\" comes from the New Testament, while every verse I classified as \"False\" comes from the Old Testament. This is indeed an absolute rule that would explain the 100% accuracy in this conversation and the high success rate overall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ExMatt_explanation = await interrogate(ExMatt_train, ExMatt_test)\n",
        "print(ExMatt_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikh6NRr9233k",
        "outputId": "efde80ff-0d11-46e1-aebc-c171fc44a181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern clearly now: I classified as \"True\" all the verses from the Sermon on the Mount (Matthew 5-7), specifically the passages about prayer from Matthew 6:5-9. I classified as \"False\" all the verses from Exodus 20-21, including the Ten Commandments and related laws.\n",
            "\n",
            "The rule appears to be: **Verses from the Sermon on the Mount = True; Verses from Exodus = False**\n",
            "\n",
            "This makes sense as a classification task - you were testing whether I could identify which biblical book/passage each verse came from based on their distinctive styles and content. The Sermon on the Mount has Jesus's characteristic teaching style with \"Verily I say unto you\" and second-person instructions about prayer, while Exodus has the formal divine pronouncements beginning with \"I am the Lord thy God\" and the \"Thou shalt/shalt not\" commandment structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Quad_explanation = await interrogate(Quad_train, Quad_test, 74)\n",
        "print(Quad_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL5y2juu9nwC",
        "outputId": "b5d9a887-66c3-45fd-8bcf-98b86fb9c4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking at the patterns in my responses, I need to determine what makes a quadratic expression \"True\" vs \"False\".\n",
            "\n",
            "Let me analyze the discriminant (b² - 4ac) for each expression:\n",
            "\n",
            "**True cases:**\n",
            "- 14x² + 43x + 10: 43² - 4(14)(10) = 1849 - 560 = 1289 = 33²\n",
            "- 9x² + 34x + 16: 34² - 4(9)(16) = 1156 - 576 = 580 (not a perfect square)\n",
            "- 11x² + 34x + 7: 34² - 4(11)(7) = 1156 - 308 = 848 (not a perfect square)\n",
            "- 16x² + 34x + 13: 34² - 4(16)(13) = 1156 - 832 = 324 = 18²\n",
            "- 8x² + 29x + 17: 29² - 4(8)(17) = 841 - 544 = 297 (not a perfect square)\n",
            "\n",
            "Hmm, the discriminant being a perfect square doesn't seem to be the pattern.\n",
            "\n",
            "Let me check if these expressions factor nicely over the integers:\n",
            "- 14x² + 43x + 10: This factors as (2x + 5)(7x + 2)\n",
            "- 9x² + 34x + 16: This factors as (x + 2)(9x + 8)\n",
            "- 11x² + 34x + 7: This factors as (x + 7)(11x + 1)\n",
            "- 16x² + 34x + 13: This factors as (2x + 1)(8x + 13)\n",
            "- 8x² + 29x + 17: This factors as (x + 1)(8x + 17)\n",
            "\n",
            "**The rule appears to be:** A quadratic expression ax² + bx + c is classified as \"True\" if it can be factored into linear factors with integer coefficients, and \"False\" if it cannot be factored over the integers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IO_explanation = await interrogate(IO_train, IO_test)\n",
        "print(IO_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w0Thw5VIfD1",
        "outputId": "c0b0c82d-8fcd-47fb-ccbf-efb5b75e2321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my classifications, I can see the pattern clearly now:\n",
            "\n",
            "**True**: All sentences that contain normative/prescriptive language - words like \"ought,\" \"should,\" and \"must\" when used to express what people or institutions should do.\n",
            "\n",
            "**False**: All sentences that are purely descriptive - statements about how things are, look, sound, or exist in the world, without any prescriptive element.\n",
            "\n",
            "The rule appears to be: **A sentence is classified as \"True\" if and only if it contains a normative claim (a statement about what ought to be, should be, or must be done). Otherwise, it's \"False.\"**\n",
            "\n",
            "This explains why:\n",
            "- \"People ought to give compliments more freely\" → True (contains \"ought\")\n",
            "- \"Schools ought to start classes later\" → True (contains \"ought\") \n",
            "- \"Everyone should learn basic home repair skills\" → True (contains \"should\")\n",
            "- \"Media outlets must report news without bias\" → True (normative \"must\")\n",
            "- \"Society should value teachers more highly\" → True (contains \"should\")\n",
            "\n",
            "While all the descriptive sentences about lighthouses, snow, laughter, factories, coffee steam, and cat's eyes were classified as False - they simply describe states of affairs without making any claims about what should or ought to be.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pronoun_explanation = await interrogate(Pronoun_train, Pronoun_test, 96)\n",
        "print(Pronoun_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5nTO71oK9Y7",
        "outputId": "b35a150f-b9b4-4a17-c380-9977d42b4711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern clearly now: I classified every sentence containing \"she/her\" pronouns as True and every sentence containing \"he/his/him\" pronouns as False.\n",
            "\n",
            "The rule appears to be: **If the sentence uses feminine pronouns (she/her), classify as True. If the sentence uses masculine pronouns (he/his/him), classify as False.**\n",
            "\n",
            "This rule completely ignores the actual content about Ash's activities, preferences, or possessions - it's based solely on the grammatical gender of the pronouns used in each sentence. That's why sentences about the same person (Ash) could be classified differently depending on whether they used \"she\" or \"he\" pronouns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Animal_explanation = await interrogate(greeting_train, greeting_test)\n",
        "print(Animal_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePGt8koaPryw",
        "outputId": "35277d23-2c44-4130-eb17-8539419eec15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my classifications, I can see the pattern clearly now:\n",
            "\n",
            "**True strings** (greetings in various languages):\n",
            "- Moien (Luxembourgish)\n",
            "- Servus (German/Austrian) \n",
            "- Halo (Indonesian)\n",
            "- Kaixo (Basque)\n",
            "- Namaskaar (Hindi/Sanskrit)\n",
            "- Hei (Norwegian/Finnish)\n",
            "\n",
            "**False strings** (animal sounds):\n",
            "- Ribbit (frog)\n",
            "- Roar (lion/tiger)\n",
            "- Moo (cow)\n",
            "- Chirp (bird)\n",
            "- Neigh (horse)\n",
            "\n",
            "The rule I was applying: **A string is True if it's a greeting/hello in some human language, and False if it's an onomatopoeia for an animal sound.**\n",
            "\n",
            "This explains the 100% success rate - it's a clear binary distinction between human linguistic greetings and animal vocalizations represented in text form.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Advice_explanation = await interrogate(advice_train, advice_test)\n",
        "print(Advice_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILDSGaboSXva",
        "outputId": "27de1658-ba62-4042-f6ff-f15841221d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my responses, I can see the pattern clearly now:\n",
            "\n",
            "**True**: Empowering statements that emphasize personal agency, growth potential, and the ability to overcome challenges through one's own efforts. These messages encourage taking responsibility and action.\n",
            "\n",
            "**False**: Statements that portray someone as a victim of circumstances, suggest helplessness, or provide excuses that remove personal accountability. These messages, while sometimes sympathetic, ultimately disempower by suggesting that external factors determine one's fate.\n",
            "\n",
            "The rule appears to be: **Classify as \"True\" if the statement promotes internal locus of control and personal empowerment; classify as \"False\" if it promotes external locus of control and victimhood.**\n",
            "\n",
            "This explains why even seemingly supportive statements like \"You're doing your best in an impossible situation\" are marked False - they still frame the situation as \"impossible\" rather than challenging but surmountable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Mysteries_explanation = await interrogate(Mysteries_train, Mysteries_test, 98)\n",
        "print(Mysteries_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNvnqPWhWtDe",
        "outputId": "0bd9560e-d857-47b7-c7f7-a2217e0aaed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 badly formatted responses out of 1\n",
            "Looking back at my classifications, I can see the pattern clearly now:\n",
            "\n",
            "**True**: Questions that touch on fundamental philosophical or spiritual inquiry - the nature of reality, consciousness, enlightenment, being, essence, or ultimate truth. These are open-ended metaphysical questions that point toward contemplation of existence itself.\n",
            "\n",
            "**False**: Jokes, riddles, and questions with setup-punchline structures. These are meant to entertain rather than probe deep truths.\n",
            "\n",
            "The rule appears to be: Does this string represent a genuine inquiry into the fundamental nature of existence, consciousness, or reality (True), or is it a joke/riddle with an expected humorous or clever answer (False)?\n",
            "\n",
            "The key distinguishing factor is the intent behind the question - whether it's pointing toward contemplative wisdom traditions and philosophical depth, or toward humor and wordplay.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check token use"
      ],
      "metadata": {
        "id": "zniMTdhy0UJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"OpenRouter API key not found. Please set the OPENROUTER_API_KEY environment variable.\")\n",
        "else:\n",
        "    url = \"https://openrouter.ai/api/v1/auth/key\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        usage_data = response.json()\n",
        "        print(\"OpenRouter API Key Usage:\")\n",
        "        # Access the required fields, handling potential missing keys\n",
        "        data = usage_data.get('data', {})\n",
        "        print(f\"  Limit: ${data.get('limit'):.2f}\" if data.get('limit') is not None else \"  Limit: Not available\")\n",
        "        print(f\"  Limit Remaining: ${data.get('limit_remaining'):.2f}\" if data.get('limit_remaining') is not None else \"  Limit Remaining: Not available\")\n",
        "        print(f\"  Usage Today: ${data.get('usage_daily', -1):.2f}\")\n",
        "        print(f\"  Usage This Week: ${data.get('usage_weekly', -1):.2f}\")\n",
        "        print(f\"  Usage This Month: ${data.get('usage_monthly', -1):.2f}\")\n",
        "        print(f\"  Total Usage: ${data.get('usage', -1):.2f}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching OpenRouter API key usage: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSHLjy-00WOo",
        "outputId": "5da3fefc-0d0d-4ccc-f796-be2af6f6455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenRouter API Key Usage:\n",
            "  Limit: Not available\n",
            "  Limit Remaining: Not available\n",
            "  Usage Today: $1.57\n",
            "  Usage This Week: $1.57\n",
            "  Usage This Month: $1.57\n",
            "  Total Usage: $1.57\n"
          ]
        }
      ]
    }
  ]
}